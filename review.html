<!DOCTYPE html>
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en"><head>

<meta charset="utf-8">
<meta name="generator" content="quarto-1.3.450">

<meta name="viewport" content="width=device-width, initial-scale=1.0, user-scalable=yes">


<title>Measuring contrast processing in the visual system using SSVEP (and VEP?)</title>
<style>
code{white-space: pre-wrap;}
span.smallcaps{font-variant: small-caps;}
div.columns{display: flex; gap: min(4vw, 1.5em);}
div.column{flex: auto; overflow-x: auto;}
div.hanging-indent{margin-left: 1.5em; text-indent: -1.5em;}
ul.task-list{list-style: none;}
ul.task-list li input[type="checkbox"] {
  width: 0.8em;
  margin: 0 0.8em 0.2em -1em; /* quarto-specific, see https://github.com/quarto-dev/quarto-cli/issues/4556 */ 
  vertical-align: middle;
}
/* CSS for citations */
div.csl-bib-body { }
div.csl-entry {
  clear: both;
}
.hanging-indent div.csl-entry {
  margin-left:2em;
  text-indent:-2em;
}
div.csl-left-margin {
  min-width:2em;
  float:left;
}
div.csl-right-inline {
  margin-left:2em;
  padding-left:1em;
}
div.csl-indent {
  margin-left: 2em;
}</style>


<script src="review_files/libs/clipboard/clipboard.min.js"></script>
<script src="review_files/libs/quarto-html/quarto.js"></script>
<script src="review_files/libs/quarto-html/popper.min.js"></script>
<script src="review_files/libs/quarto-html/tippy.umd.min.js"></script>
<script src="review_files/libs/quarto-html/anchor.min.js"></script>
<link href="review_files/libs/quarto-html/tippy.css" rel="stylesheet">
<link href="review_files/libs/quarto-html/quarto-syntax-highlighting.css" rel="stylesheet" id="quarto-text-highlighting-styles">
<script src="review_files/libs/bootstrap/bootstrap.min.js"></script>
<link href="review_files/libs/bootstrap/bootstrap-icons.css" rel="stylesheet">
<link href="review_files/libs/bootstrap/bootstrap.min.css" rel="stylesheet" id="quarto-bootstrap" data-mode="light">

  <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
  <script src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-chtml-full.js" type="text/javascript"></script>

</head>

<body class="fullcontent">

<div id="quarto-content" class="page-columns page-rows-contents page-layout-article">

<main class="content" id="quarto-document-content">

<header id="title-block-header" class="quarto-title-block default">
<div class="quarto-title">
<h1 class="title">Measuring contrast processing in the visual system using SSVEP (and VEP?)</h1>
</div>



<div class="quarto-title-meta">

    
  
    
  </div>
  

</header>

<section id="baker-wade-review-vis-neurosci" class="level2">
<h2 class="anchored" data-anchor-id="baker-wade-review-vis-neurosci">Baker, Wade: Review: Vis Neurosci</h2>
</section>
<section id="abstract" class="level2">
<h2 class="anchored" data-anchor-id="abstract">ABSTRACT:</h2>
<p>Cone photoreceptor contrast modulations are the currency of the early visual system. Measuring the way that sensitivity to contrast depends on factors such as spatial and temporal frequency, age, eccentricity, chromaticity and the presence of other stimuli has been a focus of vision science for at least 100 years. One of the most productive experimental approaches in this field has been the use of the ‘steady-state visually-evoked potential’ (SSVEP): a technique where contrast modulating inputs are ’frequency tagged (presented at well-defined frequencies and phases) and the electrical signals that they generate in the brain are analyzed in the temporal frequency domain. SSVEPs have several advantages over conventional measures of visually-evoked responses: they have relatively unambiguous ouput measures, a high SNR and they allow us to analyze interactions between stimulus components using a convenient mathematical framework. Here we describe how SSVEPs have been used to study visual contrast over the past 70 years<span class="citation" data-cites="Dawson1954">(<a href="#ref-Dawson1954" role="doc-biblioref">Dawson 1954</a>)</span>. Because our thinking about SSVEPs is best described in simple mathematical models, we embed code that illustrates key steps in the modelling and analysis. This document can therefore be used both as a review of the use of SSVEP in measuring human contrast processing, and as an interactive learning aid.</p>
</section>
<section id="introduction" class="level2">
<h2 class="anchored" data-anchor-id="introduction">INTRODUCTION:</h2>
<p>Neurons in the visual areas of the brain are primarily responsive to differences between light and dark in an image. This property, referred to as contrast, sets the fundamental limits of our visual abilities, which remain steady over a remarkably wide range of environmental light levels. The human response to contrast can be studied using many different techniques. Early work used psychophysical methods to measure contrast sensitivity <span class="citation" data-cites="Campbell1965">(<a href="#ref-Campbell1965" role="doc-biblioref">Campbell and Green 1965</a>)</span>, defined as the inverse of the lowest contrast that can be reliably detected. But neural responses can also be measured more directly using techniques such as fMRI, MEG, and EEG. Here we will describe how an EEG method known as the steady state visually evoked potential (SSVEP) technique has contributed to our understanding of human contrast processing in health, disease and throughout development.</p>
<p>The SSVEP is a continuous electrical response evoked in the brain by visual stimuli flickering at a constant frequency <span class="citation" data-cites="Regan1966">(<a href="#ref-Regan1966" role="doc-biblioref">D. Regan 1966</a>)</span>. For contrast-defined stimuli, such as sine-wave gratings, it is strongest at the occipital pole, adjacent to the early visual areas that generate the signal. The flickering stimulus entrains neural responses at multiples of the stimulus frequency, so continuous EEG data are typically analysed by taking the Fourier transform, and estimating the amplitude at these frequencies. Two common variants involve sinusoidal on-off flicker, where the stimulus alternates between a blank background and the peak contrast, and sinusoidal counterphase flicker, where the stimulus alternates in phase (i.e the black regions become white and the white regions become black). On-off flicker produces a response at the fundamental flicker frequency, known as 1F, and its integer harmonics: 2F, 3F, 4F and so on. Counterphase flicker does not produce a response at 1F, only at its even harmonics: 2F, 4F, 6F and so on. Variants involving square wave flicker can additionally produce more complex spectral components. The higher harmonics of the steady-state signal are generally thought to reflect nonlinear processing in the visual system <span class="citation" data-cites="Regan1988">(<a href="#ref-Regan1988" role="doc-biblioref">M. P. Regan and Regan 1988</a>)</span>. SSVEP signals can also be elicited by periodic changes of stimulus properties other than contrast, such as chromaticity, motion, stereo depth, and facial identity or expression <span class="citation" data-cites="Norcia2015">(see <a href="#ref-Norcia2015" role="doc-biblioref">Norcia et al. 2015</a>, for an overview)</span>; however our focus here is on the contrast response.</p>
<section id="why-measure-responses-to-contrast" class="level3">
<h3 class="anchored" data-anchor-id="why-measure-responses-to-contrast">Why measure responses to contrast?</h3>
<p>Contrast is one of the most fundamental pieces of information that the eye transmits to the brain. It can be defined as the change in cone photoreceptor activity over time (‘spatial contrast’) or space (‘spatial contrast’). Cone photoreceptors contribute to both chromatic and achromatic contrast and although most of the research we describe here focuses on achromatic contrast, SSVEPs have proven to be an excellent measure of early chromatic processing as well. [McKeefry, Baseler, DiRusso…].</p>
<p>Contrast is relatively simple to define: typically, contrast is specificed as the percentage deviation of uniform stimulus from the background. So, for example, a disk of 100 units, <span class="math inline">\(I_{\mathrm{stim}}\)</span> of cone activation surrounded by a ‘background’ of 50 units of activation <span class="math inline">\(I_{\mathrm{background}}\)</span> has a contrast of <span class="math inline">\(\frac{I_{\mathrm{stim}} - I_{\mathrm{background}}}{I_{\mathrm{background}}}\)</span> = 100%. Where patterns are more complex (for example, the sine-wave gratings or Gabors common in vision science), the Michaelson definition of contrast is specified by the maximum and minimum excursions from the mean: <span class="math display">\[{\displaystyle {\frac {I_{\mathrm {stimmax} }-I_{\mathrm {stimmin} }}{I_{\mathrm {stimmax} }+I_{\mathrm {stimmin} }}},} \]</span>. These contrast definitions are appropriate both to photometric measures of stimulus contrast (for example, luminance [LenniePokornySmith]) and also to definitions based on cone excitations [DKL, MacBoynton] which are more common in work on chromatic processing.</p>
<p>Although its definition is simple, the computations that underlie contrast processing have been the subject of intense research for many decades. The neural code for contrast, even in the earliest parts of visual cortex, is not simply a linear transform of the contrast at the retina - instead, contrast signals undergo a cascade of nonlinear processing stages that, broadly, attempt to normalise the output relative to the spatiotemporal environment. This normalization, achieved through a computation called ‘contrast gain control’ [Heeger 92, Heeger and Carandini 2011] maximises the sensitivity of the visual system by making optimal use of neuronal bandwidth. As an example, a grating seen on a low-contrast background tpyically appears more intense than the same grating when superimposed on a high contrast background. A signifcant part of research into contrast processing is concerned with how these normalization mechanisms depend on colour, orientation, eye of origin, spatial and temporal frequency, age, and the presence of neurological disorders. The SSVEP has proven to be invaliable in this research because it provides an objective readout of contrast representation at different parts of the visual system and allows us to ‘tag’ the probe and background separately.</p>
</section>
<section id="the-development-of-contrast-processing" class="level3">
<h3 class="anchored" data-anchor-id="the-development-of-contrast-processing">The development of contrast processing</h3>
<p>Because it provides a direct read-out of neural population activity, the SSVEP signal can reveal key features of neural signal transduction. By varying the peak stimulus contrast parametrically, a ‘contrast vs response’ function can be measured - where the ‘response’ is typically defined as the amplitude of the SSVEP frequency component at the stimulus frequency or a low multiple thereof. This corresponds closely to similar functions measured in single unit studies, or those measuring local field potentials invasively in the cortex. However SSVEP has the advantage that it is non-invasive, and so can be measured in awake, behaving human participants. An early use of the contrast response function was to provide an automated estimate of contrast sensitivity, without requiring behavioural responses from the participant. This was achieved by measuring the contrast response function, and extrapolating back along the function to estimate its intercept with the x-axis, which was shown to correspond with psychophysically measured detection thresholds (REFS). This general approach revealed much about the development of visual abilities in infants (Braddick), as well as deficits in neurological disease. In well-motivated adults, psychophysical measurements remain the gold standard. However, it is hard to obtain reliable psychophysical data from infants, children and adults with neuological disorders. In these cases, SSVEP measurements represent a fast and efficient method for measuring low-level visual responses.</p>
<p>In early work on infants, the ‘sweep VEP’ paradigm was developed to measure SSVEP activity in response to a stimulus that changes its properties throughout a trial, for example gradually increasing in contrast or spatial frequency. Other studies keep the stimulus properties constant for the entire trial, which avoids serial effects and makes the analysis more straightforward.</p>
<p>Figures:</p>
<div class="cell fig-cap-location-bottom" data-execution_count="1">
<div class="cell-output cell-output-display">
<div id="plotsinewaves" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="review_files/figure-html/plotsinewaves-output-1.png" width="757" height="564" class="figure-img"></p>
<figcaption class="figure-caption">a) A typical SSVEP setup: a screen, a grating, a flicker rate: b) The responses from a single electrode (time domain) c) Frequency domain</figcaption>
</figure>
</div>
</div>
</div>
<p>The two inputs are represented here as amplitude modulations across time.</p>
<p>If the two inputs are simply added together, the representation of the resulting signal in the Fourier domain is just the linear sum of the two independent signals:</p>
<div class="cell fig-cap-location-bottom" data-execution_count="2">
<div class="cell-output cell-output-display">
<div id="plotspectra" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="review_files/figure-html/plotspectra-output-1.png" width="757" height="564" class="figure-img"></p>
<figcaption class="figure-caption">a</figcaption>
</figure>
</div>
</div>
</div>
<div class="cell fig-cap-location-bottom" data-execution_count="3">
<div class="cell-output cell-output-display">
<div id="contrastresponsefunction" class="quarto-figure quarto-figure-center anchored">
<figure class="figure">
<p><img src="review_files/figure-html/contrastresponsefunction-output-1.png" width="775" height="276" class="figure-img"></p>
<figcaption class="figure-caption">a</figcaption>
</figure>
</div>
</div>
</div>
<p><em>2: Sweeps and CRFs. Measurements of contrast sensitivity, extrapolating the sweep to zero response to get t’hold. Infants and adults?</em></p>
<p><em>3: Measurements of modulation. Figures adapted from other papers: Attention to space, attention to features, adaptation (?). masking/surround suppression\</em></p>
<p><em>4: Clinical (Porciatti / Tsai/ Marmite/ Amblyopia / PD?)</em> <span class="citation" data-cites="Porciatti2000 Tsai2011">(<a href="#ref-Porciatti2000" role="doc-biblioref">Porciatti et al. 2000</a>; <a href="#ref-Tsai2011" role="doc-biblioref">Tsai et al. 2011</a>)</span> <em>5: Future directions (decoding in frequency domain?, animals? BCI?)</em></p>
<p><span id="anchor-2"></span>History</p>
<p><span id="anchor-3"></span>1. The basics of SSVEP and contrast sensitivity including a history of both fields</p>
<p>SSVEP (Steady-State Visual Evoked Potential): A continuous electrical response evoked in the brain by visual stimuli flickering at a constant frequency (Regan, 1966).</p>
<p>Contrast Sensitivity: The ability to detect differences in luminance between an object and its background (Campbell &amp; Green, 1965).</p>
<p>Regan, D. (1966). Some characteristics of average steady-state and transient responses evoked by modulated light. Electroencephalography and clinical neurophysiology, 20(3), 238-248.</p>
<p>Campbell, F. W., &amp; Green, D. G. (1965). Optical and retinal factors affecting visual resolution. J Physiology, 181, 576-593.</p>
<p>Check Regan paper for earlier (e.g.&nbsp;EEG refs). Norcia review will be helpful!</p>
<p>(From Tyler / Levi / Apkarian paper):</p>
<p>6. Regan, D.: Rapid methods for refracting the eye and assessing the visual acuity in amblyopia using steady-state visual evoked potentials. In Desmedt, J.E., editor: Visual Evoked Potentials in Man: New Developments, Oxford, 1977, Clarendon Press, pp.&nbsp;418-426.</p>
<p>7. Fricker, S.J.: Narrow-band filter techniques for the detection and measurement of evoked responses, Electroencephalogr. Clin. Neurophysiol. 14:411, 1962.</p>
<p>8. Van der Tweel, L. H., Sem-Jacobsen, C.W., Kamp, A., Van Leeuwen, W.S., and Verings, F.T.H.: Objective determination of response to modulated light, Acta Physiol. Pharmacol. Neerl. 7:528, 1958.</p>
<p>9. Regan, D.: Latencies of evoked potentials to flicker and to pattern speedily estimated by simultaneous stimulation method, Electroencephalogr. Clin. Neurophysiol. 40:654, 1976.</p>
<p>10. Tyler, C.W., Apkarian, P., and Nakayama, K.: Multiple spatial frequency tuning of electrical responses from the human.…</p>
<p>[Around here perhaps a section about what gain control is, mentioning other methods as well including psychophysics, MRI, electrophysiology, and other EEG markers including ERPs and evoked gamma band oscillations. Maybe outline the Heeger gain control model and its cousins.]</p>
<p>[Sure. But in fact gain control is only a small part of this story - especially in the early days. They were, I think, more interested in using SSVEP to measure absolute contrast sensitivity and to get lower bounds on things like infant visual development. Gain control might be better as a separate section later.]</p>
<p><span id="anchor-4"></span>2. Spatial, temporal frequency and contrast sensitivity measurements</p>
<p>Basically using SSVEP to measure a cortical output amplitude for any given input contrast. You can vary parameters like SF, TF, position, color and of course contrast. Early on people realised that you can ‘sweep’ the stimulus to get a CRF. You broadly get a line in log contrast space if you do that (Tyler) - then you can extrapolate that line down to zero response to estimate the threshold. That doesn’t &gt;quite&lt; work but it’s pretty close.</p>
<p>You can also use this for ‘difficult’ populations like babies. One interesting story was about how SSVEP become a replacement for preferential looking (which was the other way of looking at infant visual development). See e.g.&nbsp;Davida Teller. SSVEPs allowed people to make objective measurements of contrast sensitivity development and deduce that the visual system was more mature (e.g.&nbsp;more functional) in infancy than previously expected. Also measures of colour sensitivity. Tinyeyes is based off those measurements. Other people: Tyler, Norcia, Gunilla H-P, many of the people at SKERI in the 1980s and 90s. Norcia 86,88,90 - mentioned in Regan’s nice autobiography :</p>
<p>In parallel of course, people were using frequency tagging to do single unit work - the 1F vs 2F simple/complex cell classification scheme was all about this (Lennie and others).</p>
<p><span id="anchor-5"></span>3. SSVEP in functional localization</p>
<p>Techniques like fMRI have been combined with SSVEP to achieve more precise spatial localization (Di Russo et al., 2007). See however the Ales cruciform paper.</p>
<p>Di Russo, F., Pitzalis, S., Spitoni, G., Aprile, T., Patria, F., Stella, A., ... &amp; Hillyard, S. A. (2007). Identification of the neural sources of the pattern-reversal VEP. Neuroimage, 34(1), 177-189.</p>
<p>Ales and Norcia:... (showed that people’s intuition about V1 upper / lower v.f reversing polarity wasn’t really correct). This feels a little outside our scope though... We have also combined SSVEP with source imaging techniques to probe responses in different cortical locations (again, Ales papers, some early stuff from Stan K? Appelbaum, Wade, Norcia figure/ground...) and then a host of later work from that lab and others.</p>
<p><span id="anchor-6"></span>4. SSVEP and contrast gain control including adaptation, masking, and attention</p>
<p>[The story goes: Up to the lte 90s people were primarily interested in measuring contrast sensitivity - the shape of the response function was assumed to be basically log-linear - and they fit it with straight lines to extrapolate back to zero response. But then (once Heeger’s 1992 paper had sunk in - see also stuff like Shapley and Victor 1981 <a href="https://www.zotero.org/google-docs/?zAmtgj">(Shapley &amp; Victor, 1981)</a>), people started thinking about gain control - Candy and Norcia in about 1999, Porciatti, probably a load of Tyler papers that I don’t even know about...]. Probably look in p</p>
<p>And then people worked out that if you can use SSVEP to measure contrast responses, you can also use it to measure things that modulate contrast responses. These include adaptation, masking, suppression, attention (feature and space), clinical things.</p>
<p><span id="anchor-7"></span>Adaptation:</p>
<p>Continuous exposure to high-contrast patterns reduces contrast sensitivity, which can be measured using SSVEP (Ross et al., 1989). Others? Baker recent gain control paper is perhaps worth mentioning here as a ‘confound’ of sorts. Engel 2018 <a href="https://www.zotero.org/google-docs/?kdURiS"><em>(Vergeer et al., 2018)</em></a>. This paper is interesting <a href="https://www.zotero.org/google-docs/?J2EO3d"><em>(Rideaux et al., 2023)</em></a> and &gt;sort&lt; of SSVEP.</p>
<p><span id="anchor-8"></span>Masking:</p>
<p>High contrast masks can suppress the visibility of low contrast patterns, which has implications in SSVEP amplitude (Haynes et al., 2003).</p>
<p>Attention: Directing attention can enhance contrast sensitivity, as shown in studies using SSVEP (Müller et al., 2006). Also Tsai (dynamics), Baker / Wade (several), Winawer? I think JW has a nice dynamic model of normalization with some MEG data. Busse et al cat/human comparison. Candy and Norcia 2001 JNS <a href="https://www.zotero.org/google-docs/?7hhs5Z">(Candy et al., 2001)</a></p>
<p>Ross, J., Speed, H. D., &amp; Morgan, M. J. (1989). The effects of adaptation and masking on incremental thresholds for contrast. Vision research, 29(2), 205-215.</p>
<p>Haynes, J. D., Roth, G., Stadler, M., &amp; Heinze, H. J. (2003). Neuromagnetic correlates of perceived contrast in primary visual cortex. Journal of Neurophysiology, 89(6), 2655-2666.</p>
<p>Müller, M. M., Picton, T. W., Valdes-Sosa, P., Riera, J., Teder-Sälejärvi, W. A., &amp; Hillyard, S. A. (2006). Effects of spatial selective attention on the steady-state visual evoked potential in the 20–28 Hz range. Cognitive Brain Research, 24(1), 1-13.</p>
<p>5. Clinical implications</p>
<p><span id="anchor-9"></span>Clinical applications (this is a whole section)</p>
<p>Not sure exactly how SSVEP used in clinic. mfVEP?</p>
<p>, e.g., in monitoring visual impairments, tracking neuronal diseases, or neurofeedback (Norcia et al., 2015).</p>
<p>Tsai epilepsy <a href="https://www.zotero.org/google-docs/?AdhH3f">(Tsai et al., 2011)</a>. Other photosensitive epilepsy: Porciatti <a href="https://www.zotero.org/google-docs/?UTBQbV">(Porciatti et al., 2000)</a></p>
<p>Citation:</p>
<p>Migraine (Regan et al). Autism?</p>
<p>Norcia, A. M., Appelbaum, L. G., Ales, J. M., Cottereau, B. R., &amp; Rossion, B. (2015). The steady-state visual evoked potential in vision research: A review. Journal of vision, 15(6), 4-4.</p>
<p>Animal work: Flies (Eliott, West, Himmelberg, Ales, Norcia): Mice/rats (probably many - can’t think off the top of my head - we were working with a mouse EEG person at UCSF about 12 years ago...), Monkeys (Kiorpes?),</p>
<p><span id="anchor-10"></span>6. Future directions</p>
<p>Use as a readout of modulations. TMS? FUS? Marmite B12 / Fluoxetine / amblyopia in Rats,</p>
<p>GABA Huang</p>
<p>There is a lot of SSVEP interest these days because of BCIs. I think it’s pretty weak but there is &gt;so much&lt; of it that it might be worth mentioning...</p>
<p>Advanced signal processing techniques and machine learning can be integrated to improve SSVEP-based systems (Zhu et al., 2010).</p>
<p>Exploring new clinical and diagnostic applications, understanding neurological diseases, and developing novel therapeutic interventions.</p>
<p>Citation:</p>
<p>Zhu, D., Bieger, J., Molina, G. G., &amp; Aarts, R. M. (2010). A survey of stimulation methods used in SSVEP-based BCIs. Computational intelligence and neuroscience, 2010.</p>

</section>
</section>

<div id="quarto-appendix" class="default"><section class="quarto-appendix-contents" role="doc-bibliography"><h2 class="anchored quarto-appendix-heading">References</h2><div id="refs" class="references csl-bib-body hanging-indent" role="list">
<div id="ref-Campbell1965" class="csl-entry" role="listitem">
Campbell, F W, and D G Green. 1965. <span>“Optical and Retinal Factors Affecting Visual Resolution.”</span> <em>J Physiol</em> 181 (3): 576–93. <a href="https://doi.org/10.1113/jphysiol.1965.sp007784">https://doi.org/10.1113/jphysiol.1965.sp007784</a>.
</div>
<div id="ref-Dawson1954" class="csl-entry" role="listitem">
Dawson, G. D. 1954. <span>“A Summation Technique for the Detection of Small Evoked Potentials.”</span> <em>Electroencephalography and Clinical Neurophysiology</em> 6 (January): 65–84. <a href="https://doi.org/10.1016/0013-4694(54)90007-3">https://doi.org/10.1016/0013-4694(54)90007-3</a>.
</div>
<div id="ref-Norcia2015" class="csl-entry" role="listitem">
Norcia, Anthony M., L. Gregory Appelbaum, Justin M. Ales, Benoit R. Cottereau, and Bruno Rossion. 2015. <span>“The Steady-State Visual Evoked Potential in Vision Research: <span>A</span> Review.”</span> <em>Journal of Vision</em> 15 (6): 4–4. <a href="https://doi.org/10.1167/15.6.4">https://doi.org/10.1167/15.6.4</a>.
</div>
<div id="ref-Porciatti2000" class="csl-entry" role="listitem">
Porciatti, V., P. Bonanni, A. Fiorentini, and R. Guerrini. 2000. <span>“Lack of Cortical Contrast Gain Control in Human Photosensitive Epilepsy.”</span> <em>Nature Neuroscience</em> 3 (3): 259–63. <a href="https://doi.org/10.1038/72972">https://doi.org/10.1038/72972</a>.
</div>
<div id="ref-Regan1966" class="csl-entry" role="listitem">
Regan, D. 1966. <span>“Some Characteristics of Average Steady-State and Transient Responses Evoked by Modulated Light.”</span> <em>Electroencephalogr Clin Neurophysiol</em> 20 (3): 238–48. <a href="https://doi.org/10.1016/0013-4694(66)90088-5">https://doi.org/10.1016/0013-4694(66)90088-5</a>.
</div>
<div id="ref-Regan1988" class="csl-entry" role="listitem">
Regan, M. P., and D. Regan. 1988. <span>“A Frequency Domain Technique for Characterizing Nonlinearities in Biological Systems.”</span> <em>Journal of Theoretical Biology</em> 133 (3): 293–317. https://doi.org/<a href="https://doi.org/10.1016/S0022-5193(88)80323-0">https://doi.org/10.1016/S0022-5193(88)80323-0</a>.
</div>
<div id="ref-Tsai2011" class="csl-entry" role="listitem">
Tsai, Jeffrey J., Anthony M. Norcia, Justin M. Ales, and Alex R. Wade. 2011. <span>“Contrast Gain Control Abnormalities in Idiopathic Generalized Epilepsy.”</span> <em>Annals of Neurology</em> 70 (4): 574–82. <a href="https://doi.org/10.1002/ana.22462">https://doi.org/10.1002/ana.22462</a>.
</div>
</div></section></div></main>
<!-- /main column -->
<script id="quarto-html-after-body" type="application/javascript">
window.document.addEventListener("DOMContentLoaded", function (event) {
  const toggleBodyColorMode = (bsSheetEl) => {
    const mode = bsSheetEl.getAttribute("data-mode");
    const bodyEl = window.document.querySelector("body");
    if (mode === "dark") {
      bodyEl.classList.add("quarto-dark");
      bodyEl.classList.remove("quarto-light");
    } else {
      bodyEl.classList.add("quarto-light");
      bodyEl.classList.remove("quarto-dark");
    }
  }
  const toggleBodyColorPrimary = () => {
    const bsSheetEl = window.document.querySelector("link#quarto-bootstrap");
    if (bsSheetEl) {
      toggleBodyColorMode(bsSheetEl);
    }
  }
  toggleBodyColorPrimary();  
  const icon = "";
  const anchorJS = new window.AnchorJS();
  anchorJS.options = {
    placement: 'right',
    icon: icon
  };
  anchorJS.add('.anchored');
  const isCodeAnnotation = (el) => {
    for (const clz of el.classList) {
      if (clz.startsWith('code-annotation-')) {                     
        return true;
      }
    }
    return false;
  }
  const clipboard = new window.ClipboardJS('.code-copy-button', {
    text: function(trigger) {
      const codeEl = trigger.previousElementSibling.cloneNode(true);
      for (const childEl of codeEl.children) {
        if (isCodeAnnotation(childEl)) {
          childEl.remove();
        }
      }
      return codeEl.innerText;
    }
  });
  clipboard.on('success', function(e) {
    // button target
    const button = e.trigger;
    // don't keep focus
    button.blur();
    // flash "checked"
    button.classList.add('code-copy-button-checked');
    var currentTitle = button.getAttribute("title");
    button.setAttribute("title", "Copied!");
    let tooltip;
    if (window.bootstrap) {
      button.setAttribute("data-bs-toggle", "tooltip");
      button.setAttribute("data-bs-placement", "left");
      button.setAttribute("data-bs-title", "Copied!");
      tooltip = new bootstrap.Tooltip(button, 
        { trigger: "manual", 
          customClass: "code-copy-button-tooltip",
          offset: [0, -8]});
      tooltip.show();    
    }
    setTimeout(function() {
      if (tooltip) {
        tooltip.hide();
        button.removeAttribute("data-bs-title");
        button.removeAttribute("data-bs-toggle");
        button.removeAttribute("data-bs-placement");
      }
      button.setAttribute("title", currentTitle);
      button.classList.remove('code-copy-button-checked');
    }, 1000);
    // clear code selection
    e.clearSelection();
  });
  function tippyHover(el, contentFn) {
    const config = {
      allowHTML: true,
      content: contentFn,
      maxWidth: 500,
      delay: 100,
      arrow: false,
      appendTo: function(el) {
          return el.parentElement;
      },
      interactive: true,
      interactiveBorder: 10,
      theme: 'quarto',
      placement: 'bottom-start'
    };
    window.tippy(el, config); 
  }
  const noterefs = window.document.querySelectorAll('a[role="doc-noteref"]');
  for (var i=0; i<noterefs.length; i++) {
    const ref = noterefs[i];
    tippyHover(ref, function() {
      // use id or data attribute instead here
      let href = ref.getAttribute('data-footnote-href') || ref.getAttribute('href');
      try { href = new URL(href).hash; } catch {}
      const id = href.replace(/^#\/?/, "");
      const note = window.document.getElementById(id);
      return note.innerHTML;
    });
  }
      let selectedAnnoteEl;
      const selectorForAnnotation = ( cell, annotation) => {
        let cellAttr = 'data-code-cell="' + cell + '"';
        let lineAttr = 'data-code-annotation="' +  annotation + '"';
        const selector = 'span[' + cellAttr + '][' + lineAttr + ']';
        return selector;
      }
      const selectCodeLines = (annoteEl) => {
        const doc = window.document;
        const targetCell = annoteEl.getAttribute("data-target-cell");
        const targetAnnotation = annoteEl.getAttribute("data-target-annotation");
        const annoteSpan = window.document.querySelector(selectorForAnnotation(targetCell, targetAnnotation));
        const lines = annoteSpan.getAttribute("data-code-lines").split(",");
        const lineIds = lines.map((line) => {
          return targetCell + "-" + line;
        })
        let top = null;
        let height = null;
        let parent = null;
        if (lineIds.length > 0) {
            //compute the position of the single el (top and bottom and make a div)
            const el = window.document.getElementById(lineIds[0]);
            top = el.offsetTop;
            height = el.offsetHeight;
            parent = el.parentElement.parentElement;
          if (lineIds.length > 1) {
            const lastEl = window.document.getElementById(lineIds[lineIds.length - 1]);
            const bottom = lastEl.offsetTop + lastEl.offsetHeight;
            height = bottom - top;
          }
          if (top !== null && height !== null && parent !== null) {
            // cook up a div (if necessary) and position it 
            let div = window.document.getElementById("code-annotation-line-highlight");
            if (div === null) {
              div = window.document.createElement("div");
              div.setAttribute("id", "code-annotation-line-highlight");
              div.style.position = 'absolute';
              parent.appendChild(div);
            }
            div.style.top = top - 2 + "px";
            div.style.height = height + 4 + "px";
            let gutterDiv = window.document.getElementById("code-annotation-line-highlight-gutter");
            if (gutterDiv === null) {
              gutterDiv = window.document.createElement("div");
              gutterDiv.setAttribute("id", "code-annotation-line-highlight-gutter");
              gutterDiv.style.position = 'absolute';
              const codeCell = window.document.getElementById(targetCell);
              const gutter = codeCell.querySelector('.code-annotation-gutter');
              gutter.appendChild(gutterDiv);
            }
            gutterDiv.style.top = top - 2 + "px";
            gutterDiv.style.height = height + 4 + "px";
          }
          selectedAnnoteEl = annoteEl;
        }
      };
      const unselectCodeLines = () => {
        const elementsIds = ["code-annotation-line-highlight", "code-annotation-line-highlight-gutter"];
        elementsIds.forEach((elId) => {
          const div = window.document.getElementById(elId);
          if (div) {
            div.remove();
          }
        });
        selectedAnnoteEl = undefined;
      };
      // Attach click handler to the DT
      const annoteDls = window.document.querySelectorAll('dt[data-target-cell]');
      for (const annoteDlNode of annoteDls) {
        annoteDlNode.addEventListener('click', (event) => {
          const clickedEl = event.target;
          if (clickedEl !== selectedAnnoteEl) {
            unselectCodeLines();
            const activeEl = window.document.querySelector('dt[data-target-cell].code-annotation-active');
            if (activeEl) {
              activeEl.classList.remove('code-annotation-active');
            }
            selectCodeLines(clickedEl);
            clickedEl.classList.add('code-annotation-active');
          } else {
            // Unselect the line
            unselectCodeLines();
            clickedEl.classList.remove('code-annotation-active');
          }
        });
      }
  const findCites = (el) => {
    const parentEl = el.parentElement;
    if (parentEl) {
      const cites = parentEl.dataset.cites;
      if (cites) {
        return {
          el,
          cites: cites.split(' ')
        };
      } else {
        return findCites(el.parentElement)
      }
    } else {
      return undefined;
    }
  };
  var bibliorefs = window.document.querySelectorAll('a[role="doc-biblioref"]');
  for (var i=0; i<bibliorefs.length; i++) {
    const ref = bibliorefs[i];
    const citeInfo = findCites(ref);
    if (citeInfo) {
      tippyHover(citeInfo.el, function() {
        var popup = window.document.createElement('div');
        citeInfo.cites.forEach(function(cite) {
          var citeDiv = window.document.createElement('div');
          citeDiv.classList.add('hanging-indent');
          citeDiv.classList.add('csl-entry');
          var biblioDiv = window.document.getElementById('ref-' + cite);
          if (biblioDiv) {
            citeDiv.innerHTML = biblioDiv.innerHTML;
          }
          popup.appendChild(citeDiv);
        });
        return popup.innerHTML;
      });
    }
  }
});
</script>
</div> <!-- /content -->



</body></html>