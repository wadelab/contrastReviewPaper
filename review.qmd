---
title: "Measuring contrast processing in the visual system using SSVEP (and VEP?)"
format: html
bibliography: WadeBaker_Review.bib
execute:
  echo: false
---

## Baker, Wade: Review: Vis Neurosci


## ABSTRACT:

Contrast is the currency of the early visual system. Measuring the way that the computations underlying contrast processing depend on factors such as spatial and temporal frequency, age, eccentricity, chromaticity and the presence of other stimuli has been a focus of vision science for at least 100 years. One of the most productive experimental approaches in this field has been the use of the 'steady-state visually-evoked potential' (SSVEP): a technique where contrast modulating inputs are 'frequency tagged (presented at well-defined frequencies and phases) and the electrical signals that they generate in the brain are analyzed in the temporal frequency domain. SSVEPs have several advantages over conventional measures of visually-evoked responses: they have relatively unambiguous ouput measures, a high SNR and they allow us to analyze interactions between stimulus components using a convenient mathematical framework. Here we describe how SSVEPs have been used to study visual contrast over the past 70 years[@Dawson1954]. Because our thinking about SSVEPs is well-described by simple mathematical models, we embed code that illustrates key steps in the modelling and analysis. This document can therefore be used both as a review of the use of SSVEP in measuring human contrast processing, and as an interactive learning aid.

## INTRODUCTION:
Neurons in the visual areas of the brain are primarily responsive to changes in cone photoreceptor activations across time and space. This property, referred to as contrast, sets the fundamental limits of our visual abilities, which remain steady over a remarkably wide range of environmental light levels. The human response to contrast can be studied using many different techniques. Early work used psychophysical methods to measure contrast sensitivity [@Campbell1965], defined as the inverse of the lowest contrast that can be reliably detected. But neural responses can also be measured more directly using techniques such as fMRI, MEG, and EEG. Here we will describe how an EEG method known as the steady state visually evoked potential (SSVEP) technique has contributed to our understanding of human contrast processing in health, disease and throughout development.


The SSVEP is a continuous electrical response evoked in the brain by visual stimuli flickering at a constant frequency [@Regan1966]. For contrast-defined stimuli, such as sine-wave gratings, it is strongest at the occipital pole, adjacent to the early visual areas that generate the signal although careful analysis of individual VEPs reveals multiple generators throughout visual cortex [@Di Russo, Hillebrand:]. The flickering stimulus entrains neural responses at multiples of the stimulus frequency, so continuous EEG data are typically analysed by taking the Fourier transform, and estimating the amplitude at these frequencies. Two common variants involve sinusoidal on-off flicker, where the stimulus alternates between a blank background and the peak contrast, and sinusoidal counterphase flicker, where the stimulus alternates in phase (i.e the black regions become white and the white regions become black). On-off flicker can drive independent populations of on- and off-cells in the retina once per cycle and can therefore produce a response at the fundamental flicker frequency, known as 1F, and its integer harmonics: 2F, 3F, 4F and so on. Counterphase flicker contains two transients per cycle and therefore does not produce a response at 1F, only at its even harmonics: 2F, 4F, 6F and so on. Because square-waves are spectrally broad-band, square wave flicker tends to produce more complex spectral harmonics than sine-wave flicker. 

The higher harmonics of the steady-state signal are generally thought to reflect nonlinear processing in the visual system [@Regan1988]. SSVEP signals can also be elicited by periodic changes of stimulus properties other than achromatic and chromatic contrast, such as, motion, stereo depth, and facial identity or expression [see @Norcia2015, for an overview]; however our focus here is on the contrast response.

### Why measure responses to contrast?
Contrast is one of the most fundamental pieces of information that the eye transmits to the brain. It can be defined as the change in cone photoreceptor activity over time ('spatial contrast') or space ('spatial contrast'). Cone photoreceptors - which drive precortical opponent pathways -  contribute to both chromatic and achromatic contrast and although most of the research we describe here focuses on achromatic contrast, SSVEPs have proven to be an excellent measure of early chromatic processing as well. [McKeefry, Sutter, Baseler, DiRusso...]. 

Contrast is relatively simple to define: typically, contrast is specified as the percentage deviation of uniform stimulus from the background. So, for example, a disk of 100 units, $I_{\mathrm{stim}}$ of cone activation surrounded by a 'background' of 50 units of activation $I_{\mathrm{background}}$ has a contrast of $\frac{I_{\mathrm{stim}} - I_{\mathrm{background}}}{I_{\mathrm{background}}}$ = 100%. Where patterns are more complex (for example, the sine-wave gratings or Gabor patches common in vision science), the Michaelson definition of contrast is specified by the maximum and minimum excursions from the mean: $${{\frac {I_{\mathrm {stimmax} }-I_{\mathrm {stimmin} }}{I_{\mathrm {stimmax} }+I_{\mathrm {stimmin} }}},} $$. These contrast definitions are appropriate both to photometric measures of stimulus contrast (for example, luminance [LenniePokornySmith]) and also to definitions based on cone excitations [DKL, MacBoynton] which are more common in work on chromatic processing.

Although its definition as a stimulus is simple, the computations that underlie contrast processing in the brain have been the subject of intense research for many decades. The neural code for contrast, even in the earliest parts of visual cortex, is not simply a linear transform of the contrast at the retina - instead, contrast signals undergo a cascade of nonlinear processing stages that, broadly, attempt to normalise the output relative to the spatiotemporal environment. This normalization, achieved through a computation called 'contrast gain control' [Nachmas and Sansbury? Foley? Heeger 92, Heeger and Carandini 2011] maximises the sensitivity of the visual system by making optimal use of neuronal bandwidth. As an example, a grating placed at the centre of a low-contrast background typically appears more intense than the same grating when superimposed on a high contrast background.
```{python}

#| label: Perceptual gain control
#| fig-cap: The perceived contrast of a stimulus depends on its context. A high contrast surround reduces the apparent contrast of the central 'probe' region"
#| fig-cap-location: bottom
#|
import numpy as np
import matplotlib.pyplot as plt

def create_grating(size, frequency, phase, contrast):
    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))
    grating = np.sin(2 * np.pi * frequency * np.sqrt(x**2 + y**2) + phase)
    grating = (grating + 1) / 2  # Normalize to [0, 1]
    grating = grating * contrast + (1 - contrast) / 2  # Adjust contrast
    return grating

def create_circular_mask(size):
    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))
    mask = np.sqrt(x**2 + y**2) <= 0.3
    return mask

# Set parameters
size = 256
frequency = 10
phase = 0
contrast_center = 0.5
contrast_surround_low = 0.1
contrast_surround_high = 0.9

# Create gratings and circular masks
grating_center = create_grating(size, frequency, phase, contrast_center)
grating_surround_low = create_grating(size, frequency, phase, contrast_surround_low)
grating_surround_high = create_grating(size, frequency, phase, contrast_surround_high)
mask = create_circular_mask(size)

# Combine gratings and masks
image_low_contrast = grating_surround_low.copy()
image_low_contrast[mask] = grating_center[mask]
image_high_contrast = grating_surround_high.copy()
image_high_contrast[mask] = grating_center[mask]

# Create subplots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))

# Plot low-contrast background
ax1.imshow(image_low_contrast, cmap='gray', vmin=0, vmax=1)
ax1.axis('off')
ax1.set_title('Low-Contrast Background', )

# Plot high-contrast background
ax2.imshow(image_high_contrast, cmap='gray', vmin=0, vmax=1)
ax2.axis('off')
ax2.set_title('High-Contrast Background')

plt.tight_layout()
plt.show()


```


 A signifcant part of research into contrast processing is concerned with how these normalization mechanisms depend on colour, orientation, eye of origin, spatial and temporal frequency, age, and the presence of neurological disorders [refs: Chen and Foley, Petrov etc Carandini, Binocular normalization / suppression (Baker/Meese but also e.g. Heeger), Tadin, Winawer, Wade, Porciatti, Tsai...]. The SSVEP has proven to be invaliable in this research because it provides an objective readout of contrast representation at different parts of the visual system and allows us to 'tag' the probe and background separately.

Because it provides a direct read-out of neural population activity, the SSVEP signal can reveal key features of neural signal transduction. For example, by varying the peak stimulus contrast parametrically, a 'contrast vs response' function can be measured - where the 'response' is typically defined as the amplitude of the SSVEP frequency component at the stimulus frequency or a low multiple thereof. This corresponds closely to similar functions measured in single unit studies, or those measuring local field potentials invasively in the cortex[@ShapleyVictor etc]. However the SSVEP has the advantage that it is non-invasive, and so can be measured in awake, behaving human participants. 

To understand the utility of the contrast SSVEP, it is helpful to identify the cascade of processing stages in the early visual system that give rise to it. In the following section we illustrate how a typical SSVEP signal measured over early visual cortex might contain information about a large number of early visual computations. 

# Contrast processing - linear and nonlinear 

Neurons have a limited dynamic range yet they can transmit information about  visual stimuli that span many order of magnitude. In the domain of contrast, to some extent this is accomplished at a population level - individual neurons typically implement a non-linear,sigmoidal contrast vs response (CRF) transducer (@Albrecht and Hamilton1982, @Tolhurst et al1981) and different neurons exhibit peak sensitivity (defined as the maximum slope of the function) at different contrast levels [@Early matteo stuff, Busse refs]. A neuronal population will therefor span a sensitivity range greater than any individual member. 
Neurons have a limited dynamic range yet they can transmit information about visual stimuli that span many orders of magnitude. In the domain of contrast, to some extent this is accomplished at a population level - individual neurons typically implement a non-linear, sigmoidal contrast vs response (CRF) transducer and different neurons exhibit peak sensitivity (defined as the maximum slope of the function) at different contrast levels [@EarlyMatteoStuff; @BusseRefs]. A neuronal population will therefore span a sensitivity range greater than any individual member.


 Individual neurons at multiple stages of the visual hierarchy also change their sensitivity depending on the average spatiotemporal contrast energy of their environment. This "normalisation" process is dynamic and nonlinear and is well-modeled by a hyperbolic ratio function in which the response of each neuron is modulated by a local 'gain pool' composed of the summed respnses of the local neuronal population.[@Heeger 92, @Carandini and Heeger 2011 @Busse 2008, @Baker and Wade] 
Individual neurons at multiple stages of the visual hierarchy also change their sensitivity depending on the average spatiotemporal contrast energy of their environment. This "normalisation" process is dynamic and nonlinear and is well-modeled by a hyperbolic ratio function in which the response of each neuron is modulated by a local 'gain pool' composed of the summed responses of the local neuronal population [@Heeger1992; @CarandiniHeeger2011; @Busse2008; @BakerWade].

Previous figures showed how a single-input SSVEP might generate a single set of peaks in the frequency domain response which, in turn, can be used as a read-out of neuronal activity.  

Here, we show the effect of adding a second contrast component: in general, the two components interact generating nonlinear intermodulation terms at sums and differences of the input frequencies (F1, F2). The nature of the interaction --- and therefore the pattern of intermodulation terms ---  is determined by the computations happening as the contrast signal moves from retina to cortex [@Regan]

Here, we show the effect of adding a second contrast component: in general, the two components interact generating nonlinear intermodulation terms at sums and differences of the input frequencies (F1, F2). The nature of the interaction --- and therefore the pattern of intermodulation terms --- is determined by the computations happening as the contrast signal moves from retina to cortex [@Regan].
First, we implement a simple non-linear transducer with a single input to illustrate the typical signoidal shape of a contrast response function.
(Figure xx)

Next, we show that adding a second component which contributes to the gain pool of the first, results in a complex pattern of intermodulation terms.


Figures:

```{python}

#| label: plotsinewaves
#| fig-cap: "a) A typical SSVEP setup: a screen, a grating, a flicker rate: b) The responses from a single electrode (time domain) c) Frequency domain"
#| fig-cap-location: bottom
#| 
import matplotlib.pyplot as plt
import numpy as np
import scipy as scp

inputFrequencies_Hz=np.array([5,7]) # We simulate a system with two input frequencies (perhaps contrast-reversing gratings?)

duration_S=1 # All variables in this code have an _[units] where possible

digitisationRate_Hz=1000

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

inputModulations = np.zeros((len(support_S), len(inputFrequencies_Hz)))

for i, freq in enumerate(inputFrequencies_Hz):
    inputModulations[:, i] = np.sin(2 * np.pi * freq * support_S)

# Create a figure with two subplots
fig, axs = plt.subplots(len(inputFrequencies_Hz), 1, figsize=(8, 6))

# Plot each input modulation in a separate subplot
for i, freq in enumerate(inputFrequencies_Hz):
    axs[i].plot(support_S, inputModulations[:, i])
    axs[i].set_xlabel('Time (s)')
    axs[i].set_ylabel('Amplitude')
    axs[i].set_title('Frequency: {} Hz'.format(freq))

# Adjust the spacing between subplots
plt.tight_layout()
plt.show()
```


The two inputs are represented here as amplitude modulations across time. 

If the two inputs are simply added together, the representation of the resulting signal in the Fourier domain is just the linear sum of the two independent signals. However, it is important to take physiology into account. If we ignore cells sensitive to contrast transients, contrast is represented as a combination of rectified signals from 'on and 'off'-sensitive cells (broadly, cells that code positive or negative changes in spatiotemporal luminance). To model the population response of these cells to a contrast-reversing luminance sine wave, we therefore introduce an initial full-wave rectification stage that simulates the outputs of two, equal populations of on- and off-polarity detectors. Once this is done, we see that the FT of the resulting signal contains power only at the second harmonics and above. It is possible to generate first-hamonic responses in contrast-response SSVEPs but only when the inputs are modulated in an 'on/off' manner rather than contrast reversed. 

```{python}

#| label: plotspectra
#| fig-cap: "Temporal frequency representations of combining two inputs at frequencies F1=5Hz and F2=7Hz combination. A pure sine-wave input would generate responses only at F1 and F2. However, the rectification that accompanies early visual processing converts this contrast reversal into a more complex frequency-domain representation with power predominantly at the second harmonics 2F1 and 2F2"
#| fig-cap-location: bottom

#| label: plotsinewaves
#| fig-cap: "a) A typical SSVEP setup: a screen, a grating, a flicker rate: b) The responses from a single electrode (time domain) c) Frequency domain"
#| fig-cap-location: bottom
#| 
import matplotlib.pyplot as plt
import numpy as np
import scipy as scp

inputFrequencies_Hz=np.array([5,7]) # We simulate a system with two input frequencies (perhaps contrast-reversing gratings?)

duration_S=1 # All variables in this code have an _[units] where possible

digitisationRate_Hz=1000

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

inputModulations = np.zeros((len(support_S), len(inputFrequencies_Hz)))
for i, freq in enumerate(inputFrequencies_Hz):
    inputModulations[:, i] = np.sin(2 * np.pi * freq * support_S)

freqCutoff_Hz=30
combinedSignal=np.sum(inputModulations,axis=1)
combinedRectifiedSignal=np.sum(np.abs(inputModulations), axis=1)
FT_combinedSignal=np.fft.fft(combinedSignal)/len(combinedSignal)
FT_combinedRectifiedSignal=np.fft.fft(combinedRectifiedSignal)/len(combinedSignal)
fig,axs=plt.subplots(1,4,figsize=(8,3))
axs[0].plot(support_S,combinedSignal)
axs[0].set_xlabel('Time (s)')
axs[0].set_ylabel('Amplitude (a.u.)')
axs[0].set_title('Input signals:\nlinear combination')

# Create the frequency support for the FFT plot
frequencySupport = np.arange(1,freqCutoff_Hz*duration_S+1) # We only want to plot the frequencies in the FFT up to this point

# Plot the absolute values of the FFT in the second axis as a bar plot
axs[1].bar(frequencySupport, np.abs(FT_combinedSignal[frequencySupport]))
axs[1].set_xlabel('Frequency (Hz)')
axs[1].set_ylabel('Magnitude (a.u.)')
axs[1].set_title('FFT\n linear combination')
# Plot the absolute values of the FFT in the second axis as a bar plot

axs[2].plot(support_S,combinedRectifiedSignal)
axs[2].set_xlabel('Time (s)')
axs[2].set_ylabel('Amplitude (a.u.)')
axs[2].set_title('Sum rectified inputs')

axs[3].bar(frequencySupport, np.abs(FT_combinedRectifiedSignal[frequencySupport]))
axs[3].set_xlabel('Frequency (Hz)')
axs[3].set_ylabel('Magnitude (a.u.)')
axs[3].set_title('FFT of\n sum rectified inputs')

plt.tight_layout()
plt.show()


```

Even without considering a spatial component, the early visual system is far more complex than the model here suggests. For example as well as cells that code positive or negative contrast in a more or less continuous manner, the retina also contains 'transient' cells that code termporal changes in contrast. These cells (@ Movshon? Levitt? Earlier... Kuffler? H+W? Alpern?) will introduce second harmonic components even when the stimulus itself is modulated in an on-off fashion. Analogously, in the spatial domain, so-called 'simple cells' are sensitive to the polarity of a spatial contrast modulation while 'complex cells' respond to the presence of patterned spatial contrast irrespective of its spatial position. The SSVEP response to a contrast-reversing sine-wave grating therefore contains information about nonlinear computations performed across a range of retinal and cortical cell types.


One of the simplest nonlinearities is the response function that describes a cell's response to different levels of contrast. In Figure xxx this is modeled as described above by a hyperbolic ratio function resulting in a saturating non-linearity. 
${R{\mathrm{max}}}\frac{C{\mathrm{in}}^n}{C{\mathrm{in}}^n+ C{\mathrm{50}}^n}$ where ${R{\mathrm{max}}}$ describes the maximum response level, $C{\mathrm{50}}$ is the 'semi-saturation constant' (the point at which the reponse is at half-maximum) and n controls the steepness of the curve.


```{python}

#| label: ContrastResponseFunction
#| fig-cap: "Non-linear contrast response function resulting from the population average of two full-wave rectified signals passing through a non-linear transducer. Note the 'supersaturation' at high contrast levels."
#| fig-cap-location: bottom


import matplotlib.pyplot as plt
from matplotlib import colormaps
import numpy as np
import scipy as scp


def simpleTransducerFunction(inputContrast, c50, RMax):
 # Here we model a simple hyperbolic ratio function. Also called a "Naka-Rushton" function.
 # RMax defines the reponse gain of the transducer (how big the biggest output is). 
 # c50 defines the conrast sensitivity. Smaller values are more sensitive.
 # The exponent can also vary - here we fix it to 2
  expnt=2

  # Contrast cannot be negative. To model the responses of a set of on and off 
  # contrast detectors we perform full-wave rectification of the signal
  inputContrast=np.abs(inputContrast)
  output=RMax*(inputContrast**expnt)/(inputContrast**expnt + c50**expnt)
  return output

# Define some constants
inputFrequency_Hz=np.array([5]) # We simulate a system with on input at many different contrasts
contrastRange=np.logspace(0,1.5,20)/100 # Equally spaced log contrast between 1 and 10^1.5
duration_S=1 # All variables in this code have an _[units] where possible
digitisationRate_Hz=1000
freqCutoff_Hz=30
c50=.10
RMax=10

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

initialSignal=[] # Create lists to hold the initial contrast representation and the result of passign it through a simple Naka-Rushton function
transducedSignal=[]

fig, axs = plt.subplots(1,3, figsize=(8, 3))

initialSignal = np.zeros(len(contrastRange))
transducedSignal = np.zeros(len(contrastRange))
for contrastIndex,thisContrast in enumerate(contrastRange):
  inputModulation = np.sin(2 * np.pi * inputFrequency_Hz * support_S) * thisContrast

  axs[0].plot(support_S, inputModulation)

  FT_Signal = np.fft.fft(inputModulation) / len(inputModulation)
 
  inputAmplitude = np.abs(FT_Signal[inputFrequency_Hz])
  initialSignal[contrastIndex]=inputAmplitude[0] 

   # Now compute the FT on the signal after it has passed through a single non-linearity. Do this 
   # using the transducer functiona above.
  transducedModulation=simpleTransducerFunction(inputModulation, c50,RMax)
  FT_transducedModulation=np.fft.fft(transducedModulation)/ len(transducedModulation)
  transducedAmplitude = np.abs(FT_transducedModulation[inputFrequencies_Hz*2])
  transducedSignal[contrastIndex]=transducedAmplitude[0]

axs[0].set_title('Sine-wave responses at\n different contrast levels', fontsize=10)

axs[1].plot(contrastRange,initialSignal)
axs[1].set_xlabel('Contrast')
axs[1].set_ylabel('Amplitude (a.u.)')
axs[1].set_title('Linear computation stage', fontsize=10)
axs[1].grid()

axs[2].plot(contrastRange,transducedSignal)
axs[2].set_xlabel('Contrast')
axs[2].set_ylabel('Amplitude (a.u.)')
axs[2].set_title('After nonlinear transducer', fontsize=10)

axs[2].grid()
plt.tight_layout()
plt.show()


```

The hyperbolic ratio function is monotonic but the CRF resulting from measuring the amplitude of the 2F component contains slight roll-off  at high input contrasts. This results from the distortion of the input sine waves at high contrast due to a combination of the full-wave rectification and saturating non-linearity. Power at other harmonics increases and the total power generated by the input is monotonic. This roll-off is often seen in experimental data and has been referred to as 'supersaturation' [@Tyler].

To illustrate the effect of contrast gain control[@Heeger92], we include a second component that contributes to the gain pool of the first. At a single pair of (matched) contrast levels, we see a complex pattern of intermodulation terms in the FT.

```{python}
#| label: Intermodulation
#| fig-cap: "Non-linear combination of two independent contrast modulations at F1 and F2 results in 'intermodulation' terms that appear at low-order sums and differences of those frequencies"
#| fig-cap-location: bottom

import matplotlib.pyplot as plt
from matplotlib import colormaps
import numpy as np
import scipy as scp


def simpleTransducerFunction(inputContrast, maskContrast, c50, RMax):
 # Here we model a simple hyperbolic ratio function. Also called a "Naka-Rushton" function.
 # RMax defines the reponse gain of the transducer (how big the biggest output is). 
 # c50 defines the conrast sensitivity. Smaller values are more sensitive.
 # The exponent can also vary - here we fix it to 2
  expnt=2
  inputContrast=np.abs(inputContrast)
  maskContrast=np.abs(maskContrast)

  output=RMax*(inputContrast**expnt)/(inputContrast**expnt + maskContrast**expnt + c50**expnt)
  return output

# Define some constants
inputFrequency_Hz=np.array([5,7]) # We simulate a system with two inputs at a single contrast
inputContrasts=np.array([.2 ,.2])
duration_S=1 # All variables in this code have an _[units] where possible
digitisationRate_Hz=1000
freqCutoff_Hz=30
c50=.10
RMax=10

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

initialSignal=[] # Create lists to hold the initial contrast representation and the result of passign it through a simple Naka-Rushton function
transducedSignal=[]

fig, axs = plt.subplots(1,3, figsize=(8, 3))

inputModulation = np.sin(2 * np.pi * inputFrequency_Hz[0] * support_S) * inputContrasts[0]
maskModulation =  np.sin(2 * np.pi * inputFrequency_Hz[1] * support_S) * inputContrasts[1]

axs[0].plot(support_S, inputModulation,'k')
axs[0].plot(support_S, maskModulation,'r')
axs[0].set_title('Input modulations', fontsize=10)
axs[0].grid()

combinedSignal=simpleTransducerFunction(inputModulation, maskModulation, c50,RMax)
FT_combinedSignal=np.abs(np.fft.fft(combinedSignal)/ len(combinedSignal))
axs[1].plot(support_S, combinedSignal,'k')
axs[1].set_title('Combined signal after transducer', fontsize=10)
axs[1].grid()

axs[2].bar(np.arange(1,19), FT_combinedSignal[1:19])

axs[2].grid()
plt.tight_layout()
plt.show()


```

The complexity of even a simple simulation of the frequency-domain signal arising from non-linear interactions is intriguing. Presumably, the signal measured from early visual cortex contains is the result of a cascade of nonlinear retinal and cortical operations up to that point and therefore contains a 'signature' of the computational nature, order and parameters of those operations - including the shape of the transducer functions and the computations involved in signal combination. In principle, that information could be recovered from the SSVEP signal. 

This possibility was recognised in the early days of the technique [@reganandRegan1988]. Although characterising the complete set of computations along entire processing pathway is problematic, careful parametric variation of the input stimuli does allow us to fit models of early visual gain control using SSVEP data. ... MORE HERE - Although this idea was suggested as early as 1988 (probably earlier) not many people seem to have done it much. Candy and Norcia (in infants) 2001, Busse et al2008, Tsai/Norcia/Wade 2010s, Then lots of Baker stuff including the CerebCort paper. : Focusing only on SSVEP: [@NorciaCandy2001, @Regan1990?  ] 




### Measuring the development of contrast processing

An early use of the SSVEP was to provide an objective estimate of spatial contrast sensitivity in infants, without requiring behavioural responses. 

In well-motivated adults, psychophysical measurements of contrast sensitivity remain the gold standard. However, it is difficult and time consuming to obtain reliable psychophysical data from infants. In these cases, SSVEP measurements represent a fast and efficient method for measuring low-level visual responses [@Norcia, Tyler, Braddick] and the high SNR of SSVEP means that infants need only look at the screen for short periods of time. 

Because SSVEP response at detection threshold are very small, estimating this threshold is achieved by measuring the contrast response function at relatively high levels, and extrapolating back along the function (either contrast vs response measured at a constant spatial frequency or spatial frequency vs response at a constant contrast level) to estimate its intercept with the x-axis. This contrast level was shown to correspond approximately with psychophysically measured detection thresholds [@DaleNorciaTyler86]. 

Measuring the SSVEP at multiple levels was made faster by the development of the ‘sweep VEP’ paradigm in which the stimulus changed its contrast, spatial frequency or some other property, throughout a trial [@Tyler, Nakayama etc 1979]. To avoid hysteresis effects, the sweep is sometimes conducted both up and down in the same experiment [Tyler, Norcia etc: 1985, 1990 etc]. 

This general approach has revealed much about the development of visual abilities in infants [@braddick, @atkinson]. In general, SSVEP measurements of infant vision have revealed that contrast sensitivity for both achromatic and chromatic contrast as well as stereoscopic depth perception develops earlier than had been supposed previously based on behavioural readouts [@dobsonVisualAcuityHuman1978; @norciaSpatialFrequencySweep1985, ] with both chromatic and achromatic contrast detection reaching near-adult levels by around six months while spatial acuity as measured by SSVEP reaches adult levels more slowly but near-adult levels are recorded around 1 year [@NorciaTyler1985, @HamerVisRed1989] compared to  around 6-7 years with behavioural measures [@Ellemberg vis res 1999, @Atkinson]. At least some of this difference is likely due to the relatively objectivity and high SNR of the SSVEP technique compared to other methods such as preferential looking which require careful measurement of the infant's gaze direction although it should be noted that other groups have reported electrophysiological correlates of visual acuity that more closely match the behavioural measures [@de1982maturation].
 
The SSVEP technique has also been used to study the development of the contrast gain control mechanisms described in the previous section.[@Candy 2001, @PeiNorcia 2017]. Although contrast gain control is measurable in infants as young as six weeks old (@Candy2001, @MorroneBurr1986, @Skoczenski & Norcia, 1998), development appears to be slower with adult levels being reached in approximately 11 years. [@PeiNorcia].


```{python}

#| label: SweepVEP Deteection threshold estimate
#| fig-cap: "Sweep VEP simulation showing how a contrast detection threshold can be estimated from sweep VEP data measured at higher contrasts"
#| fig-cap-location: bottom


import matplotlib.pyplot as plt
from matplotlib import colormaps
import numpy as np
import scipy as scp
from sklearn.linear_model import LinearRegression



def simpleTransducerFunction(inputContrast, c50, RMax):
 # Here we model a simple hyperbolic ratio function. Also called a "Naka-Rushton" function.
 # RMax defines the reponse gain of the transducer (how big the biggest output is). 
 # c50 defines the conrast sensitivity. Smaller values are more sensitive.
 # The exponent can also vary - here we fix it to 2
  expnt=2
  output=RMax*(inputContrast**expnt)/(inputContrast**expnt + c50**expnt)
  return output

# Define some constants
nLevels=8
internalNoise=1
inputFrequency_Hz=np.array([5]) # We simulate a system with on input at many different contrasts
contrastRange=np.logspace(1,1.9,nLevels)/100 # Equally spaced log contrast between 1 and 10^1.5
duration_S=1 # All variables in this code have an _[units] where possible
digitisationRate_Hz=1000
freqCutoff_Hz=30

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)


fig, axs = plt.subplots(1,1, figsize=(4, 3))

initialSignal = np.zeros(len(contrastRange))
transducedSignal = np.zeros(len(contrastRange))
for contrastIndex,thisContrast in enumerate(contrastRange):
  inputModulation = np.sin(2 * np.pi * inputFrequency_Hz * support_S) * thisContrast + np.random.rand(len(support_S))*internalNoise

  FT_Signal = np.fft.fft(inputModulation) / len(inputModulation)

  responseAmplitude = np.abs(FT_Signal[inputFrequency_Hz])
  initialSignal[contrastIndex]=responseAmplitude[0]
  transducedSignal[contrastIndex]=simpleTransducerFunction(responseAmplitude[0], 0.05, 10)

# Now fit a linear regression to the first 4 contrast levels (before it saturates) and find out where this crosses the Y-axis
X = np.log10(contrastRange[:4]).reshape(-1, 1)
y = transducedSignal[:4]
reg = LinearRegression().fit(X, y)
x_intercept = 10 ** (-reg.intercept_ / reg.coef_[0])

axs.set_title(f'Simulated sweep VEP at {nLevels} different contrasts', fontsize=10)
axs.semilogx(contrastRange, transducedSignal, 'o')
axs.semilogx(contrastRange[:4], reg.predict(X), 'r--', label='Linear Fit')
axs.semilogx([x_intercept], [0], 'ro', label='Threshold')
axs.set_xlabel('Contrast')
axs.set_ylabel('Amplitude (a.u.)')
axs.set_xlim(0.01, 1)
axs.set_ylim(0, 10)
axs.legend()
axs.grid()
plt.tight_layout()
plt.show()



```

The sweep VEP (technically, the sweep 'SSVEP') technique is now commonly-used to obtain a rapid and objective measurement of visual acuity. Because of its relative speed and simplicity, this technique has now become a standard for conducting tests of visual acuity in very young subjects or where behavioural tests are not appropriate [@Ridder2004 Diva vs Enfant, @Hoffman, @Bach and @Farmer].
The sweep VEP (really, a sweep 'SSVEP') technique is now commonly-used to obtain a rapid and objective measurement of visual acuity. In particular, because of its relative speed and simplicity, this technique has now become a standard for conducting tests of visual acuity in very young subjects or where behavioural tests are not appropriate [@Ridder2004; @Hoffman; @Bach; @Farmer].

## 



*2: Sweeps and CRFs. Measurements of contrast sensitivity, extrapolating
the sweep to zero response to get t'hold. Infants and adults?*

*3: Measurements of modulation. Figures adapted from other papers:
Attention to space, attention to features, adaptation (?).
masking/surround suppression\\*

*4: Clinical (Porciatti / Tsai/ Marmite/ Amblyopia / PD?)*
[@Porciatti2000; @Tsai2011]
*5: Future directions (decoding in frequency domain?, animals? BCI?)*


[]{#anchor-2}History

[]{#anchor-3}1. The basics of SSVEP and contrast sensitivity including a
history of both fields

SSVEP (Steady-State Visual Evoked Potential): A continuous electrical
response evoked in the brain by visual stimuli flickering at a constant
frequency (Regan, 1966).

Contrast Sensitivity: The ability to detect differences in luminance
between an object and its background (Campbell \& Green, 1965).

Regan, D. (1966). Some characteristics of average steady-state and
transient responses evoked by modulated light. Electroencephalography
and clinical neurophysiology, 20(3), 238-248.

Campbell, F. W., \& Green, D. G. (1965). Optical and retinal factors
affecting visual resolution. J Physiology, 181, 576-593.

Check Regan paper for earlier (e.g. EEG refs). Norcia review will be
helpful!

(From Tyler / Levi / Apkarian paper):

6\. Regan, D.: Rapid methods for refracting the eye and assessing the
visual acuity in amblyopia using steady-state visual evoked potentials.
In Desmedt, J.E., editor: Visual Evoked Potentials in Man: New
Developments, Oxford, 1977, Clarendon Press, pp. 418-426.

7\. Fricker, S.J.: Narrow-band filter techniques for the detection and
measurement of evoked responses, Electroencephalogr. Clin. Neurophysiol.
14:411, 1962.

8\. Van der Tweel, L. H., Sem-Jacobsen, C.W., Kamp, A., Van Leeuwen,
W.S., and Verings, F.T.H.: Objective determination of response to
modulated light, Acta Physiol. Pharmacol. Neerl. 7:528, 1958.

9\. Regan, D.: Latencies of evoked potentials to flicker and to pattern
speedily estimated by simultaneous stimulation method,
Electroencephalogr. Clin. Neurophysiol. 40:654, 1976.

10\. Tyler, C.W., Apkarian, P., and Nakayama, K.: Multiple spatial
frequency tuning of electrical responses from the human\....

\[Around here perhaps a section about what gain control is, mentioning
other methods as well including psychophysics, MRI, electrophysiology,
and other EEG markers including ERPs and evoked gamma band oscillations.
Maybe outline the Heeger gain control model and its cousins.\]

\[Sure. But in fact gain control is only a small part of this story -
especially in the early days. They were, I think, more interested in
using SSVEP to measure absolute contrast sensitivity and to get lower
bounds on things like infant visual development. Gain control might be
better as a separate section later.\]

[]{#anchor-4}2. Spatial, temporal frequency and contrast sensitivity
measurements

Basically using SSVEP to measure a cortical output amplitude for any
given input contrast. You can vary parameters like SF, TF, position,
color and of course contrast. Early on people realised that you can
'sweep' the stimulus to get a CRF. You broadly get a line in log
contrast space if you do that (Tyler) - then you can extrapolate that
line down to zero response to estimate the threshold. That doesn't
\>quite\< work but it's pretty close.

You can also use this for 'difficult' populations like babies. One
interesting story was about how SSVEP become a replacement for
preferential looking (which was the other way of looking at infant
visual development). See e.g. Davida Teller. SSVEPs allowed people to
make objective measurements of contrast sensitivity development and
deduce that the visual system was more mature (e.g. more functional) in
infancy than previously expected. Also measures of colour sensitivity.
Tinyeyes is based off those measurements. Other people: Tyler, Norcia,
Gunilla H-P, many of the people at SKERI in the 1980s and 90s. Norcia
86,88,90 - mentioned in Regan's nice autobiography :

In parallel of course, people were using frequency tagging to do single
unit work - the 1F vs 2F simple/complex cell classification scheme was
all about this (Lennie and others).

[]{#anchor-5}3. SSVEP in functional localization

Techniques like fMRI have been combined with SSVEP to achieve more
precise spatial localization (Di Russo et al., 2007). See however the
Ales cruciform paper.

Di Russo, F., Pitzalis, S., Spitoni, G., Aprile, T., Patria, F., Stella,
A., \... \& Hillyard, S. A. (2007). Identification of the neural sources
of the pattern-reversal VEP. Neuroimage, 34(1), 177-189.

Ales and Norcia:\... (showed that people's intuition about V1 upper /
lower v.f reversing polarity wasn't really correct). This feels a little
outside our scope though\... We have also combined SSVEP with source
imaging techniques to probe responses in different cortical locations
(again, Ales papers, some early stuff from Stan K? Appelbaum, Wade,
Norcia figure/ground\...) and then a host of later work from that lab
and others.

[]{#anchor-6}4. SSVEP and contrast gain control including adaptation,
masking, and attention

\[The story goes: Up to the lte 90s people were primarily interested in
measuring contrast sensitivity - the shape of the response function was
assumed to be basically log-linear - and they fit it with straight lines
to extrapolate back to zero response. But then (once Heeger's 1992 paper
had sunk in - see also stuff like Shapley and Victor 1981 [(Shapley \&
Victor, 1981)](https://www.zotero.org/google-docs/?zAmtgj)), people
started thinking about gain control - Candy and Norcia in about 1999,
Porciatti, probably a load of Tyler papers that I don't even know
about\...\]. Probably look in p

And then people worked out that if you can use SSVEP to measure contrast
responses, you can also use it to measure things that modulate contrast
responses. These include adaptation, masking, suppression, attention
(feature and space), clinical things.

[]{#anchor-7}Adaptation:

Continuous exposure to high-contrast patterns reduces contrast
sensitivity, which can be measured using SSVEP (Ross et al., 1989).
Others? Baker recent gain control paper is perhaps worth mentioning here
as a 'confound' of sorts. Engel 2018 [*(Vergeer et al.,
2018)*](https://www.zotero.org/google-docs/?kdURiS). This paper is
interesting [*(Rideaux et al.,
2023)*](https://www.zotero.org/google-docs/?J2EO3d) and \>sort\< of
SSVEP.

[]{#anchor-8}Masking:

High contrast masks can suppress the visibility of low contrast
patterns, which has implications in SSVEP amplitude (Haynes et al.,
2003).

Attention: Directing attention can enhance contrast sensitivity, as
shown in studies using SSVEP (Müller et al., 2006). Also Tsai
(dynamics), Baker / Wade (several), Winawer? I think JW has a nice
dynamic model of normalization with some MEG data. Busse et al cat/human
comparison. Candy and Norcia 2001 JNS [(Candy et al.,
2001)](https://www.zotero.org/google-docs/?7hhs5Z)

Ross, J., Speed, H. D., \& Morgan, M. J. (1989). The effects of
adaptation and masking on incremental thresholds for contrast. Vision
research, 29(2), 205-215.

Haynes, J. D., Roth, G., Stadler, M., \& Heinze, H. J. (2003).
Neuromagnetic correlates of perceived contrast in primary visual cortex.
Journal of Neurophysiology, 89(6), 2655-2666.

Müller, M. M., Picton, T. W., Valdes-Sosa, P., Riera, J.,
Teder-Sälejärvi, W. A., \& Hillyard, S. A. (2006). Effects of spatial
selective attention on the steady-state visual evoked potential in the
20--28 Hz range. Cognitive Brain Research, 24(1), 1-13.

5\. Clinical implications

[]{#anchor-9}Clinical applications (this is a whole section)

Not sure exactly how SSVEP used in clinic. mfVEP?

, e.g., in monitoring visual impairments, tracking neuronal diseases, or
neurofeedback (Norcia et al., 2015).

Tsai epilepsy [(Tsai et al.,
2011)](https://www.zotero.org/google-docs/?AdhH3f). Other photosensitive
epilepsy: Porciatti [(Porciatti et al.,
2000)](https://www.zotero.org/google-docs/?UTBQbV)

Citation:

Migraine (Regan et al). Autism?

Norcia, A. M., Appelbaum, L. G., Ales, J. M., Cottereau, B. R., \&
Rossion, B. (2015). The steady-state visual evoked potential in vision
research: A review. Journal of vision, 15(6), 4-4.

Animal work: Flies (Eliott, West, Himmelberg, Ales, Norcia): Mice/rats
(probably many - can't think off the top of my head - we were working
with a mouse EEG person at UCSF about 12 years ago\...), Monkeys
(Kiorpes?),

[]{#anchor-10}6. Future directions

Use as a readout of modulations. TMS? FUS? Marmite B12 / Fluoxetine /
amblyopia in Rats,

GABA Huang

There is a lot of SSVEP interest these days because of BCIs. I think
it's pretty weak but there is \>so much\< of it that it might be worth
mentioning\...

Advanced signal processing techniques and machine learning can be
integrated to improve SSVEP-based systems (Zhu et al., 2010).

Exploring new clinical and diagnostic applications, understanding
neurological diseases, and developing novel therapeutic interventions.

Citation:

Zhu, D., Bieger, J., Molina, G. G., \& Aarts, R. M. (2010). A survey of
stimulation methods used in SSVEP-based BCIs. Computational intelligence
and neuroscience, 2010.




