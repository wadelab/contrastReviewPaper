---
title: "Measuring contrast processing in the visual system using SSVEP (and VEP?)"
format: html
bibliography: WadeBaker_Review.bib
execute:
  echo: false
---

## Baker, Wade: Review: Vis Neurosci


## ABSTRACT:

Contrast is the currency of the early visual system. Measuring the way that the computations underlying contrast processing depend on factors such as spatial and temporal frequency, age, eccentricity, chromaticity and the presence of other stimuli has been a focus of vision science for at least 100 years. One of the most productive experimental approaches in this field has been the use of the 'steady-state visually-evoked potential' (SSVEP): a technique where contrast modulating inputs are 'frequency tagged (presented at well-defined frequencies and phases) and the electrical signals that they generate in the brain are analyzed in the temporal frequency domain. SSVEPs have several advantages over conventional measures of visually-evoked responses: they have relatively unambiguous ouput measures, a high SNR and they allow us to analyze interactions between stimulus components using a convenient mathematical framework. Here we describe how SSVEPs have been used to study visual contrast over the past 70 years[@Dawson1954]. Because our thinking about SSVEPs is well-described by simple mathematical models, we embed code that illustrates key steps in the modelling and analysis. This document can therefore be used both as a review of the use of SSVEP in measuring human contrast processing, and as an interactive learning aid.

## INTRODUCTION:
Neurons in the visual areas of the brain are primarily responsive to changes in cone photoreceptor activations across time and space. This property, referred to as contrast, sets the fundamental limits of our visual abilities, which remain steady over a remarkably wide range of environmental light levels. The human response to contrast can be studied using many different techniques. Early work used psychophysical methods to measure contrast sensitivity [@Campbell1965], defined as the inverse of the lowest contrast that can be reliably detected. But neural responses can also be measured more directly using techniques such as fMRI, MEG, and EEG. Here we will describe how an EEG method known as the steady state visually evoked potential (SSVEP) technique has contributed to our understanding of human contrast processing in health, disease and throughout development.


The SSVEP is a continuous electrical response evoked in the brain by visual stimuli flickering at a constant frequency [@Regan1966]. For contrast-defined stimuli, such as sine-wave gratings, it is strongest at the occipital pole, adjacent to the early visual areas that generate the signal although careful analysis of individual VEPs reveals multiple generators throughout visual cortex [@Di Russo, Hillebrand:]. The flickering stimulus entrains neural responses at multiples of the stimulus frequency, so continuous EEG data are typically analysed by taking the Fourier transform, and estimating the amplitude at these frequencies. Two common variants involve sinusoidal on-off flicker, where the stimulus alternates between a blank background and the peak contrast, and sinusoidal counterphase flicker, where the stimulus alternates in phase (i.e the black regions become white and the white regions become black). On-off flicker can drive independent populations of on- and off-cells in the retina once per cycle and can therefore produce a response at the fundamental flicker frequency, known as 1F, and its integer harmonics: 2F, 3F, 4F and so on. Counterphase flicker contains two transients per cycle and therefore does not produce a response at 1F, only at its even harmonics: 2F, 4F, 6F and so on. Because square-waves are spectrally broad-band, square wave flicker tends to produce more complex spectral harmonics than sine-wave flicker. 

The higher harmonics of the steady-state signal are generally thought to reflect nonlinear processing in the visual system [@Regan1988]. SSVEP signals can also be elicited by periodic changes of stimulus properties other than achromatic and chromatic contrast, such as, motion, stereo depth, and facial identity or expression [see @Norcia2015, for an overview]; however our focus here is on the contrast response.

### Why measure responses to contrast?
Contrast is one of the most fundamental pieces of information that the eye transmits to the brain. It can be defined as the change in cone photoreceptor activity over time ('spatial contrast') or space ('spatial contrast'). Cone photoreceptors - which drive precortical opponent pathways -  contribute to both chromatic and achromatic contrast and although most of the research we describe here focuses on achromatic contrast, SSVEPs have proven to be an excellent measure of early chromatic processing as well. [McKeefry, Sutter, Baseler, DiRusso...]. 

Contrast is relatively simple to define: typically, contrast is specified as the percentage deviation of uniform stimulus from the background. So, for example, a disk of 100 units, $I_{\mathrm{stim}}$ of cone activation surrounded by a 'background' of 50 units of activation $I_{\mathrm{background}}$ has a contrast of $\frac{I_{\mathrm{stim}} - I_{\mathrm{background}}}{I_{\mathrm{background}}}$ = 100%. Where patterns are more complex (for example, the sine-wave gratings or Gabor patches common in vision science), the Michaelson definition of contrast is specified by the maximum and minimum excursions from the mean: $${{\frac {I_{\mathrm {stimmax} }-I_{\mathrm {stimmin} }}{I_{\mathrm {stimmax} }+I_{\mathrm {stimmin} }}},} $$. These contrast definitions are appropriate both to photometric measures of stimulus contrast (for example, luminance [LenniePokornySmith]) and also to definitions based on cone excitations [DKL, MacBoynton] which are more common in work on chromatic processing.

Although its definition as a stimulus is simple, the computations that underlie contrast processing in the brain have been the subject of intense research for many decades. The neural code for contrast, even in the earliest parts of visual cortex, is not simply a linear transform of the contrast at the retina - instead, contrast signals undergo a cascade of nonlinear processing stages that, broadly, attempt to normalise the output relative to the spatiotemporal environment. This normalization, achieved through a computation called 'contrast gain control' [Heeger 92, Heeger and Carandini 2011] maximises the sensitivity of the visual system by making optimal use of neuronal bandwidth. As an example, a grating placed at the centre of a low-contrast background tpyically appears more intense than the same grating when superimposed on a high contrast background.
```{python}
import numpy as np
import matplotlib.pyplot as plt

def create_grating(size, frequency, phase, contrast):
    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))
    grating = np.sin(2 * np.pi * frequency * np.sqrt(x**2 + y**2) + phase)
    grating = (grating + 1) / 2  # Normalize to [0, 1]
    grating = grating * contrast + (1 - contrast) / 2  # Adjust contrast
    return grating

def create_circular_mask(size):
    x, y = np.meshgrid(np.linspace(-1, 1, size), np.linspace(-1, 1, size))
    mask = np.sqrt(x**2 + y**2) <= 0.3
    return mask

# Set parameters
size = 256
frequency = 10
phase = 0
contrast_center = 0.5
contrast_surround_low = 0.1
contrast_surround_high = 0.9

# Create gratings and circular masks
grating_center = create_grating(size, frequency, phase, contrast_center)
grating_surround_low = create_grating(size, frequency, phase, contrast_surround_low)
grating_surround_high = create_grating(size, frequency, phase, contrast_surround_high)
mask = create_circular_mask(size)

# Combine gratings and masks
image_low_contrast = grating_surround_low.copy()
image_low_contrast[mask] = grating_center[mask]
image_high_contrast = grating_surround_high.copy()
image_high_contrast[mask] = grating_center[mask]

# Create subplots
fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(7, 3))

# Plot low-contrast background
ax1.imshow(image_low_contrast, cmap='gray', vmin=0, vmax=1)
ax1.axis('off')
ax1.set_title('Low-Contrast Background', )

# Plot high-contrast background
ax2.imshow(image_high_contrast, cmap='gray', vmin=0, vmax=1)
ax2.axis('off')
ax2.set_title('High-Contrast Background')

plt.tight_layout()
plt.show()


```


 A signifcant part of research into contrast processing is concerned with how these normalization mechanisms depend on colour, orientation, eye of origin, spatial and temporal frequency, age, and the presence of neurological disorders [refs: Chen and Foley, Petrov etc Carandini, Binocular normalization / suppression (Baker/Meese but also e.g. Heeger), Tadin, Winawer, Wade, Porciatti, Tsai...]. The SSVEP has proven to be invaliable in this research because it provides an objective readout of contrast representation at different parts of the visual system and allows us to 'tag' the probe and background separately.

Because it provides a direct read-out of neural population activity, the SSVEP signal can reveal key features of neural signal transduction. For example, by varying the peak stimulus contrast parametrically, a 'contrast vs response' function can be measured - where the 'response' is typically defined as the amplitude of the SSVEP frequency component at the stimulus frequency or a low multiple thereof. This corresponds closely to similar functions measured in single unit studies, or those measuring local field potentials invasively in the cortex[@ShapleyVictor etc]. However the SSVEP has the advantage that it is non-invasive, and so can be measured in awake, behaving human participants. 

### Measuring the development of contrast processing

An early use of the contrast response function was to provide an objective estimate of spatial contrast sensitivity in infants, without requiring behavioural responses. 

In well-motivated adults, psychophysical measurements of contrast sensitivity remain the gold standard. However, it is difficult and time consuming to obtain reliable psychophysical data from infants. In these cases, SSVEP measurements represent a fast and efficient method for measuring low-level visual responses [Norcia, Tyler, Braddick] and the high SNR of SSVEP means that infants need only look at the screen for short periods of time. 

Because SSVEP response at detection threshold are very small, estimating this threshold is achieved by measuring the contrast response function at relatively high levels, and extrapolating back along the function (either contrast vs response measured at a constant spatial frequency or spatial frequency vs response at a constant contrast level) to estimate its intercept with the x-axis. This contrast level was shown to correspond approximately with psychophysically measured detection thresholds [@DaleNorciaTyler86]. 

Measuring the SSVEP at multiple levels was made faster by the development of the ‘sweep VEP’ paradigm in which the stimulus changed its contrast, spatial frequency or some other property, throughout a trial [@Tyler, Nakayama etc 1979]. To avoid hysteresis effects, the sweep is sometimes conducted both up and down in the same experiment [Tyler, Norcia etc: 1985, 1990 etc]. 

This general approach has revealed much about the development of visual abilities in infants [@braddick, @atkinson]. In general, SSVEP measurements of infant vision have revealed that spatial acuity for both achromatic and chromatic contrast as well as stereoscopic depth perception develops earlier than had been supposed previously based on behavioural readouts [@dobsonVisualAcuityHuman1978; @norciaSpatialFrequencySweep1985, ] with both chromatic and achromatic contrast detection reaching near-adult levels by around six months. At least some of this difference is likely due to the relatively objectivity and high SNR of the SSVEP technique compared to other methods such as preferential looking which require careful measurement of the infant's gaze direction. One open question is how more complex contrast computations develop - and in particular how the human brain develop the tightly-tuned 'gain control' mechanisms that allow it to detect and discriminate contrast across very different visual scenes.

```{python}

#| label: SweepVEP Deteection threshold estimate
#| fig-cap: "a"
#| fig-cap-location: bottom


import matplotlib.pyplot as plt
from matplotlib import colormaps
import numpy as np
import scipy as scp
from sklearn.linear_model import LinearRegression



def simpleTransducerFunction(inputContrast, c50, RMax):
 # Here we model a simple hyperbolic ratio function. Also called a "Naka-Rushton" function.
 # RMax defines the reponse gain of the transducer (how big the biggest output is). 
 # c50 defines the conrast sensitivity. Smaller values are more sensitive.
 # The exponent can also vary - here we fix it to 2
  expnt=2
  output=RMax*(inputContrast**expnt)/(inputContrast**expnt + c50**expnt)
  return output

# Define some constants
nLevels=8
internalNoise=1
inputFrequency_Hz=np.array([5]) # We simulate a system with on input at many different contrasts
contrastRange=np.logspace(1,1.9,nLevels)/100 # Equally spaced log contrast between 1 and 10^1.5
duration_S=1 # All variables in this code have an _[units] where possible
digitisationRate_Hz=1000
freqCutoff_Hz=30

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)


fig, axs = plt.subplots(1,1, figsize=(4, 3))

initialSignal = np.zeros(len(contrastRange))
transducedSignal = np.zeros(len(contrastRange))
for contrastIndex,thisContrast in enumerate(contrastRange):
  inputModulation = np.sin(2 * np.pi * inputFrequency_Hz * support_S) * thisContrast + np.random.rand(len(support_S))*internalNoise

  FT_Signal = np.fft.fft(inputModulation) / len(inputModulation)

  responseAmplitude = np.abs(FT_Signal[inputFrequency_Hz])
  initialSignal[contrastIndex]=responseAmplitude[0]
  transducedSignal[contrastIndex]=simpleTransducerFunction(responseAmplitude[0], 0.05, 10)

# Now fit a linear regression to the first 4 contrast levels (before it saturates) and find out where this crosses the Y-axis
X = np.log10(contrastRange[:4]).reshape(-1, 1)
y = transducedSignal[:4]
reg = LinearRegression().fit(X, y)
x_intercept = 10 ** (-reg.intercept_ / reg.coef_[0])

axs.set_title(f'Simulated sweep VEP at {nLevels} different contrasts', fontsize=10)
axs.semilogx(contrastRange, transducedSignal, 'o')
axs.semilogx(contrastRange[:4], reg.predict(X), 'r--', label='Linear Fit')
axs.semilogx([x_intercept], [0], 'ro', label='Threshold')
axs.set_xlabel('Contrast')
axs.set_ylabel('Amplitude (a.u.)')
axs.set_xlim(0.01, 1)
axs.set_ylim(0, 10)
axs.legend()
axs.grid()
plt.tight_layout()
plt.show()



```

The sweep VEP (really, a sweep 'SSVEP') technique is now commonly-used to obtain a rapid and objective measurement of visual acuity. In particular, because of its relative speed and simplicity, this technique has now become a standard for conducting tests of visual acuity in very young subjects or where behavioural tests are not appropriate [@Ridder2004 Diva vs Enfant, @Hoffman, @Bach and @Farmer].

# Contrast processing - linear and nonlinear 

Neurons have a limited dynamic range yet they can transmit information about  visual stimuli that span many order of magnitude. In the domain of contrast, to some extent this is accomplished at a population level - individual neurons typically implement a non-linear,sigmoidal contrast vs response (CRF) transducer and different neurons exhibit peak sensitivity (the maximum slope of the function) at different contrast levels [@Early matteo stuff, Busse refs]. Individual neurons at multiple stages of the visual hierarchy also change their sensitivity depending on the average spatiotemporal contrast energy of their environment. This normalisation process is dynamic and nonlinear and is well-modeled by a hyperbolic ratio function in which the response of each neuron is modulated by a local 'gain pool' composed of the summed respnses of the local neuronal population.[@Heeger 92, @Carandini and Heeger 2011 @Busse 2008, @Baker and Wade] 

Previous figures showed how a single-input SSVEP might generate a single set of peaks in the frequency domain response which, in turn, can be used as a read-out of neuronal activity.  

Here, we show that adding a second contrast component can generate intermodulation and that the two components interact. The nature of the interaction is determined by the precise computations happening as the contrast signal moves from retina to cortex.

Figures:

```{python}

#| label: plotsinewaves
#| fig-cap: "a) A typical SSVEP setup: a screen, a grating, a flicker rate: b) The responses from a single electrode (time domain) c) Frequency domain"
#| fig-cap-location: bottom
#| 
import matplotlib.pyplot as plt
import numpy as np
import scipy as scp

inputFrequencies_Hz=np.array([5,7]) # We simulate a system with two input frequencies (perhaps contrast-reversing gratings?)

duration_S=1 # All variables in this code have an _[units] where possible

digitisationRate_Hz=1000

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

inputModulations = np.zeros((len(support_S), len(inputFrequencies_Hz)))

for i, freq in enumerate(inputFrequencies_Hz):
    inputModulations[:, i] = np.sin(2 * np.pi * freq * support_S)

# Create a figure with two subplots
fig, axs = plt.subplots(len(inputFrequencies_Hz), 1, figsize=(8, 6))

# Plot each input modulation in a separate subplot
for i, freq in enumerate(inputFrequencies_Hz):
    axs[i].plot(support_S, inputModulations[:, i])
    axs[i].set_xlabel('Time (s)')
    axs[i].set_ylabel('Amplitude')
    axs[i].set_title('Frequency: {} Hz'.format(freq))

# Adjust the spacing between subplots
plt.tight_layout()
plt.show()
```


The two inputs are represented here as amplitude modulations across time. 

If the two inputs are simply added together, the representation of the resulting signal in the Fourier domain is just the linear sum of the two independent signals:

```{python}

#| label: plotspectra
#| fig-cap: "a"
#| fig-cap-location: bottom

#| label: plotsinewaves
#| fig-cap: "a) A typical SSVEP setup: a screen, a grating, a flicker rate: b) The responses from a single electrode (time domain) c) Frequency domain"
#| fig-cap-location: bottom
#| 
import matplotlib.pyplot as plt
import numpy as np
import scipy as scp

inputFrequencies_Hz=np.array([5,7]) # We simulate a system with two input frequencies (perhaps contrast-reversing gratings?)

duration_S=1 # All variables in this code have an _[units] where possible

digitisationRate_Hz=1000

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

inputModulations = np.zeros((len(support_S), len(inputFrequencies_Hz)))
for i, freq in enumerate(inputFrequencies_Hz):
    inputModulations[:, i] = np.sin(2 * np.pi * freq * support_S)

freqCutoff_Hz=30
combinedSignal=np.sum(inputModulations,axis=1)
FT_combinedSignal=np.fft.fft(combinedSignal)/len(combinedSignal)
fig,axs=plt.subplots(1,2,figsize=(8,6))
axs[0].plot(support_S,combinedSignal)
axs[0].set_xlabel('Time (s)')
axs[0].set_ylabel('Amplitude (a.u.)')
axs[0].set_title('Input signals with linear combination')

# Create the frequency support for the FFT plot
frequencySupport = np.arange(1,freqCutoff_Hz*duration_S+1) # We only want to plot the frequencies in the FFT up to this point

# Plot the absolute values of the FFT in the second axis as a bar plot
axs[1].bar(frequencySupport, np.abs(FT_combinedSignal[frequencySupport]))
axs[1].set_xlabel('Frequency (Hz)')
axs[1].set_ylabel('Magnitude (a.u.)')
axs[1].set_title('FFT of Combined Signal')

plt.tight_layout()
plt.show()


```

```{python}

#| label: ContrastResponseFunction
#| fig-cap: "a"
#| fig-cap-location: bottom

#| label: plotsinewaves
#| fig-cap: "a) A typical SSVEP setup: a screen, a grating, a flicker rate: b) The responses from a single electrode (time domain) c) Frequency domain"
#| fig-cap-location: bottom
#| 
import matplotlib.pyplot as plt
from matplotlib import colormaps
import numpy as np
import scipy as scp


def simpleTransducerFunction(inputContrast, c50, RMax):
 # Here we model a simple hyperbolic ratio function. Also called a "Naka-Rushton" function.
 # RMax defines the reponse gain of the transducer (how big the biggest output is). 
 # c50 defines the conrast sensitivity. Smaller values are more sensitive.
 # The exponent can also vary - here we fix it to 2
  expnt=2.5
  output=RMax*(inputContrast**expnt)/(inputContrast**expnt + c50**expnt)
  return output

# Define some constants
inputFrequency_Hz=np.array([5]) # We simulate a system with on input at many different contrasts
contrastRange=np.logspace(0,1.5,20)/100 # Equally spaced log contrast between 1 and 10^1.5
duration_S=1 # All variables in this code have an _[units] where possible
digitisationRate_Hz=1000
freqCutoff_Hz=30

support_S=np.linspace(0,duration_S,duration_S*digitisationRate_Hz)

initialSignal=[] # Create lists to hold the initial contrast representation and the result of passign it through a simple Naka-Rushton function
transducedSignal=[]

fig, axs = plt.subplots(1,3, figsize=(8, 3))

initialSignal = np.zeros(len(contrastRange))
transducedSignal = np.zeros(len(contrastRange))
for contrastIndex,thisContrast in enumerate(contrastRange):
  inputModulation = np.sin(2 * np.pi * inputFrequency_Hz * support_S) * thisContrast

  axs[0].plot(support_S, inputModulation)

  FT_Signal = np.fft.fft(inputModulation) / len(inputModulation)

  responseAmplitude = np.abs(FT_Signal[inputFrequency_Hz])
  initialSignal[contrastIndex]=responseAmplitude[0]
  transducedSignal[contrastIndex]=simpleTransducerFunction(responseAmplitude[0], 0.05, 10)
axs[0].set_title('Sine-wave responses at\n different contrast levels', fontsize=10)



axs[1].plot(contrastRange,initialSignal)
axs[1].set_xlabel('Contrast')
axs[1].set_ylabel('Amplitude (a.u.)')
axs[1].set_title('Linear computation stage', fontsize=10)
axs[1].grid()

axs[2].plot(contrastRange,transducedSignal)
axs[2].set_xlabel('Contrast')
axs[2].set_ylabel('Amplitude (a.u.)')
axs[2].set_title('After nonlinear transducer', fontsize=10)

axs[2].grid()
plt.tight_layout()
plt.show()


```

*2: Sweeps and CRFs. Measurements of contrast sensitivity, extrapolating
the sweep to zero response to get t'hold. Infants and adults?*

*3: Measurements of modulation. Figures adapted from other papers:
Attention to space, attention to features, adaptation (?).
masking/surround suppression\\*

*4: Clinical (Porciatti / Tsai/ Marmite/ Amblyopia / PD?)*
[@Porciatti2000; @Tsai2011]
*5: Future directions (decoding in frequency domain?, animals? BCI?)*


[]{#anchor-2}History

[]{#anchor-3}1. The basics of SSVEP and contrast sensitivity including a
history of both fields

SSVEP (Steady-State Visual Evoked Potential): A continuous electrical
response evoked in the brain by visual stimuli flickering at a constant
frequency (Regan, 1966).

Contrast Sensitivity: The ability to detect differences in luminance
between an object and its background (Campbell \& Green, 1965).

Regan, D. (1966). Some characteristics of average steady-state and
transient responses evoked by modulated light. Electroencephalography
and clinical neurophysiology, 20(3), 238-248.

Campbell, F. W., \& Green, D. G. (1965). Optical and retinal factors
affecting visual resolution. J Physiology, 181, 576-593.

Check Regan paper for earlier (e.g. EEG refs). Norcia review will be
helpful!

(From Tyler / Levi / Apkarian paper):

6\. Regan, D.: Rapid methods for refracting the eye and assessing the
visual acuity in amblyopia using steady-state visual evoked potentials.
In Desmedt, J.E., editor: Visual Evoked Potentials in Man: New
Developments, Oxford, 1977, Clarendon Press, pp. 418-426.

7\. Fricker, S.J.: Narrow-band filter techniques for the detection and
measurement of evoked responses, Electroencephalogr. Clin. Neurophysiol.
14:411, 1962.

8\. Van der Tweel, L. H., Sem-Jacobsen, C.W., Kamp, A., Van Leeuwen,
W.S., and Verings, F.T.H.: Objective determination of response to
modulated light, Acta Physiol. Pharmacol. Neerl. 7:528, 1958.

9\. Regan, D.: Latencies of evoked potentials to flicker and to pattern
speedily estimated by simultaneous stimulation method,
Electroencephalogr. Clin. Neurophysiol. 40:654, 1976.

10\. Tyler, C.W., Apkarian, P., and Nakayama, K.: Multiple spatial
frequency tuning of electrical responses from the human\....

\[Around here perhaps a section about what gain control is, mentioning
other methods as well including psychophysics, MRI, electrophysiology,
and other EEG markers including ERPs and evoked gamma band oscillations.
Maybe outline the Heeger gain control model and its cousins.\]

\[Sure. But in fact gain control is only a small part of this story -
especially in the early days. They were, I think, more interested in
using SSVEP to measure absolute contrast sensitivity and to get lower
bounds on things like infant visual development. Gain control might be
better as a separate section later.\]

[]{#anchor-4}2. Spatial, temporal frequency and contrast sensitivity
measurements

Basically using SSVEP to measure a cortical output amplitude for any
given input contrast. You can vary parameters like SF, TF, position,
color and of course contrast. Early on people realised that you can
'sweep' the stimulus to get a CRF. You broadly get a line in log
contrast space if you do that (Tyler) - then you can extrapolate that
line down to zero response to estimate the threshold. That doesn't
\>quite\< work but it's pretty close.

You can also use this for 'difficult' populations like babies. One
interesting story was about how SSVEP become a replacement for
preferential looking (which was the other way of looking at infant
visual development). See e.g. Davida Teller. SSVEPs allowed people to
make objective measurements of contrast sensitivity development and
deduce that the visual system was more mature (e.g. more functional) in
infancy than previously expected. Also measures of colour sensitivity.
Tinyeyes is based off those measurements. Other people: Tyler, Norcia,
Gunilla H-P, many of the people at SKERI in the 1980s and 90s. Norcia
86,88,90 - mentioned in Regan's nice autobiography :

In parallel of course, people were using frequency tagging to do single
unit work - the 1F vs 2F simple/complex cell classification scheme was
all about this (Lennie and others).

[]{#anchor-5}3. SSVEP in functional localization

Techniques like fMRI have been combined with SSVEP to achieve more
precise spatial localization (Di Russo et al., 2007). See however the
Ales cruciform paper.

Di Russo, F., Pitzalis, S., Spitoni, G., Aprile, T., Patria, F., Stella,
A., \... \& Hillyard, S. A. (2007). Identification of the neural sources
of the pattern-reversal VEP. Neuroimage, 34(1), 177-189.

Ales and Norcia:\... (showed that people's intuition about V1 upper /
lower v.f reversing polarity wasn't really correct). This feels a little
outside our scope though\... We have also combined SSVEP with source
imaging techniques to probe responses in different cortical locations
(again, Ales papers, some early stuff from Stan K? Appelbaum, Wade,
Norcia figure/ground\...) and then a host of later work from that lab
and others.

[]{#anchor-6}4. SSVEP and contrast gain control including adaptation,
masking, and attention

\[The story goes: Up to the lte 90s people were primarily interested in
measuring contrast sensitivity - the shape of the response function was
assumed to be basically log-linear - and they fit it with straight lines
to extrapolate back to zero response. But then (once Heeger's 1992 paper
had sunk in - see also stuff like Shapley and Victor 1981 [(Shapley \&
Victor, 1981)](https://www.zotero.org/google-docs/?zAmtgj)), people
started thinking about gain control - Candy and Norcia in about 1999,
Porciatti, probably a load of Tyler papers that I don't even know
about\...\]. Probably look in p

And then people worked out that if you can use SSVEP to measure contrast
responses, you can also use it to measure things that modulate contrast
responses. These include adaptation, masking, suppression, attention
(feature and space), clinical things.

[]{#anchor-7}Adaptation:

Continuous exposure to high-contrast patterns reduces contrast
sensitivity, which can be measured using SSVEP (Ross et al., 1989).
Others? Baker recent gain control paper is perhaps worth mentioning here
as a 'confound' of sorts. Engel 2018 [*(Vergeer et al.,
2018)*](https://www.zotero.org/google-docs/?kdURiS). This paper is
interesting [*(Rideaux et al.,
2023)*](https://www.zotero.org/google-docs/?J2EO3d) and \>sort\< of
SSVEP.

[]{#anchor-8}Masking:

High contrast masks can suppress the visibility of low contrast
patterns, which has implications in SSVEP amplitude (Haynes et al.,
2003).

Attention: Directing attention can enhance contrast sensitivity, as
shown in studies using SSVEP (Müller et al., 2006). Also Tsai
(dynamics), Baker / Wade (several), Winawer? I think JW has a nice
dynamic model of normalization with some MEG data. Busse et al cat/human
comparison. Candy and Norcia 2001 JNS [(Candy et al.,
2001)](https://www.zotero.org/google-docs/?7hhs5Z)

Ross, J., Speed, H. D., \& Morgan, M. J. (1989). The effects of
adaptation and masking on incremental thresholds for contrast. Vision
research, 29(2), 205-215.

Haynes, J. D., Roth, G., Stadler, M., \& Heinze, H. J. (2003).
Neuromagnetic correlates of perceived contrast in primary visual cortex.
Journal of Neurophysiology, 89(6), 2655-2666.

Müller, M. M., Picton, T. W., Valdes-Sosa, P., Riera, J.,
Teder-Sälejärvi, W. A., \& Hillyard, S. A. (2006). Effects of spatial
selective attention on the steady-state visual evoked potential in the
20--28 Hz range. Cognitive Brain Research, 24(1), 1-13.

5\. Clinical implications

[]{#anchor-9}Clinical applications (this is a whole section)

Not sure exactly how SSVEP used in clinic. mfVEP?

, e.g., in monitoring visual impairments, tracking neuronal diseases, or
neurofeedback (Norcia et al., 2015).

Tsai epilepsy [(Tsai et al.,
2011)](https://www.zotero.org/google-docs/?AdhH3f). Other photosensitive
epilepsy: Porciatti [(Porciatti et al.,
2000)](https://www.zotero.org/google-docs/?UTBQbV)

Citation:

Migraine (Regan et al). Autism?

Norcia, A. M., Appelbaum, L. G., Ales, J. M., Cottereau, B. R., \&
Rossion, B. (2015). The steady-state visual evoked potential in vision
research: A review. Journal of vision, 15(6), 4-4.

Animal work: Flies (Eliott, West, Himmelberg, Ales, Norcia): Mice/rats
(probably many - can't think off the top of my head - we were working
with a mouse EEG person at UCSF about 12 years ago\...), Monkeys
(Kiorpes?),

[]{#anchor-10}6. Future directions

Use as a readout of modulations. TMS? FUS? Marmite B12 / Fluoxetine /
amblyopia in Rats,

GABA Huang

There is a lot of SSVEP interest these days because of BCIs. I think
it's pretty weak but there is \>so much\< of it that it might be worth
mentioning\...

Advanced signal processing techniques and machine learning can be
integrated to improve SSVEP-based systems (Zhu et al., 2010).

Exploring new clinical and diagnostic applications, understanding
neurological diseases, and developing novel therapeutic interventions.

Citation:

Zhu, D., Bieger, J., Molina, G. G., \& Aarts, R. M. (2010). A survey of
stimulation methods used in SSVEP-based BCIs. Computational intelligence
and neuroscience, 2010.




